{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c3e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step5_visualize_results.py\n",
    "\"\"\"\n",
    "Visualize SVM classification results.\n",
    "Saves plots to OUTPUT_DIR.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57187762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_curve, auc, RocCurveDisplay\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ea88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- User config ----------\n",
    "OUTPUT_DIR = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\correlation_outputs\"\n",
    "MODEL_PATH = os.path.join(OUTPUT_DIR, \"svm_best_model.joblib\")\n",
    "CSV_PATH = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\mushroom.csv\"  # fallback if pre-split not used\n",
    "USE_PRE_SPLIT = False  # if you saved X_test/y_test CSVs set True and script will try to load them\n",
    "PLOT_DPI = 150\n",
    "RANDOM_STATE = 42\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4bc2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd85ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Load model and data ----------\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    raise SystemExit(f\"Model not found at {MODEL_PATH}. Run Task 4 to save svm_best_model.joblib first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ca7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(MODEL_PATH)\n",
    "print(\"Loaded model:\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1680a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data (prefer pre-split files if available)\n",
    "if USE_PRE_SPLIT:\n",
    "    base = os.path.dirname(CSV_PATH)\n",
    "    x_test_path = os.path.join(base, \"X_test.csv\")\n",
    "    y_test_path = os.path.join(base, \"y_test.csv\")\n",
    "    if os.path.exists(x_test_path) and os.path.exists(y_test_path):\n",
    "        X_test = pd.read_csv(x_test_path)\n",
    "        y_test = pd.read_csv(y_test_path).iloc[:, 0].values\n",
    "    else:\n",
    "        raise SystemExit(\"Pre-split test files requested but not found.\")\n",
    "else:\n",
    "    # load full CSV and split here to reproduce same split as Task 4\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    if 'class' not in df.columns:\n",
    "        raise SystemExit(\"Target column 'class' not found in CSV.\")\n",
    "    y = df['class'].astype(str)\n",
    "    X = df.drop(columns=['class'])\n",
    "    # encode y to 0/1 same logic as training script\n",
    "    if set(y.unique()) <= set(['e', 'p']):\n",
    "        y_encoded = (y == 'p').astype(int).values\n",
    "    else:\n",
    "        unique = sorted(y.unique())\n",
    "        mapping = {unique[0]: 0, unique[1]: 1}\n",
    "        y_encoded = y.map(mapping).values\n",
    "    X_encoded = pd.get_dummies(X, drop_first=False)\n",
    "    # ensure columns line up (if training used same encoding)\n",
    "    # If model was trained on a different feature set, prefer using saved pre-split CSVs.\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_encoded, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cc85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "X_test_arr = np.asarray(X_test)\n",
    "y_test_arr = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610e8f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Predictions ----------\n",
    "y_pred = model.predict(X_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48798f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_arr, y_pred)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9855881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save confusion matrix (counts)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=[\"pred_0\",\"pred_1\"], yticklabels=[\"true_0\",\"true_1\"])\n",
    "plt.ylabel(\"True\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix (counts)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"svm_confusion_matrix_counts.png\"), dpi=PLOT_DPI)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7963969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save normalized confusion matrix (percent)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues', cbar=False,\n",
    "            xticklabels=[\"pred_0\",\"pred_1\"], yticklabels=[\"true_0\",\"true_1\"])\n",
    "plt.ylabel(\"True\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix (normalized)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"svm_confusion_matrix_normalized.png\"), dpi=PLOT_DPI)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b550c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report heatmap (turn report into a dataframe)\n",
    "report = classification_report(y_test_arr, y_pred, output_dict=True, zero_division=0)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "# Save textual report\n",
    "with open(os.path.join(OUTPUT_DIR, \"svm_classification_report.txt\"), \"w\") as f:\n",
    "    f.write(classification_report(y_test_arr, y_pred, zero_division=0))\n",
    "report_df.to_csv(os.path.join(OUTPUT_DIR, \"svm_classification_report_table.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48612f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot classification report (precision, recall, f1) for classes\n",
    "metrics_df = report_df.loc[['0','1'], ['precision','recall','f1-score']].astype(float)\n",
    "plt.figure(figsize=(6,4))\n",
    "metrics_df.plot(kind='bar')\n",
    "plt.title(\"Precision / Recall / F1-score by Class\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"svm_class_metrics_bar.png\"), dpi=PLOT_DPI)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0c937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- ROC curve & AUC ----------\n",
    "y_score = None\n",
    "if hasattr(model, \"decision_function\"):\n",
    "    try:\n",
    "        y_score = model.decision_function(X_test_arr)\n",
    "    except Exception:\n",
    "        y_score = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c470b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_score is None and hasattr(model, \"predict_proba\"):\n",
    "    try:\n",
    "        y_score = model.predict_proba(X_test_arr)[:, 1]\n",
    "    except Exception:\n",
    "        y_score = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0562a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_score is not None:\n",
    "    fpr, tpr, _ = roc_curve(y_test_arr, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'AUC = {roc_auc:.4f}')\n",
    "    plt.plot([0,1], [0,1], linestyle='--', color='gray', linewidth=1)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"svm_roc_auc.png\"), dpi=PLOT_DPI)\n",
    "    plt.close()\n",
    "    print(\"Saved ROC curve. AUC:\", roc_auc)\n",
    "else:\n",
    "    print(\"Model does not expose decision_function or predict_proba. ROC curve skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe7d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 2D Embeddings (PCA and t-SNE) colored by true/predicted ----------\n",
    "# PCA (fast)\n",
    "pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "try:\n",
    "    X_2d_pca = pca.fit_transform(X_test_arr)\n",
    "    df_plot = pd.DataFrame({\n",
    "        'pc1': X_2d_pca[:,0],\n",
    "        'pc2': X_2d_pca[:,1],\n",
    "        'true': y_test_arr,\n",
    "        'pred': y_pred\n",
    "    })\n",
    "    # True labels\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.scatterplot(data=df_plot, x='pc1', y='pc2', hue='true', style='true', s=40, palette='deep')\n",
    "    plt.title('PCA 2D - True labels')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"svm_pca_true_labels.png\"), dpi=PLOT_DPI)\n",
    "    plt.close()\n",
    "\n",
    "    # Predicted labels\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.scatterplot(data=df_plot, x='pc1', y='pc2', hue='pred', style='pred', s=40, palette='deep')\n",
    "    plt.title('PCA 2D - Predicted labels')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"svm_pca_pred_labels.png\"), dpi=PLOT_DPI)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(\"PCA embedding failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78295363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE (slower; sample if too big)\n",
    "tsne_n = min(2000, X_test_arr.shape[0])  # cap samples for speed\n",
    "if X_test_arr.shape[0] > tsne_n:\n",
    "    sample_idx = np.random.RandomState(RANDOM_STATE).choice(X_test_arr.shape[0], size=tsne_n, replace=False)\n",
    "    X_sample = X_test_arr[sample_idx]\n",
    "    y_sample = y_test_arr[sample_idx]\n",
    "    y_pred_sample = y_pred[sample_idx]\n",
    "else:\n",
    "    X_sample = X_test_arr\n",
    "    y_sample = y_test_arr\n",
    "    y_pred_sample = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a585359",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tsne = TSNE(n_components=2, perplexity=30, random_state=RANDOM_STATE, init='pca')\n",
    "    X_2d_tsne = tsne.fit_transform(X_sample)\n",
    "    df_tsne = pd.DataFrame({\n",
    "        'tsne1': X_2d_tsne[:,0],\n",
    "        'tsne2': X_2d_tsne[:,1],\n",
    "        'true': y_sample,\n",
    "        'pred': y_pred_sample\n",
    "    })\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.scatterplot(data=df_tsne, x='tsne1', y='tsne2', hue='true', s=30, palette='tab10')\n",
    "    plt.title('t-SNE (true labels)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"svm_tsne_true_labels.png\"), dpi=PLOT_DPI)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.scatterplot(data=df_tsne, x='tsne1', y='tsne2', hue='pred', s=30, palette='tab10')\n",
    "    plt.title('t-SNE (predicted labels)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"svm_tsne_pred_labels.png\"), dpi=PLOT_DPI)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(\"t-SNE embedding failed or too slow:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09398c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All visualizations saved to:\", OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
