{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84110f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "step4_svm.py\n",
    "Task 4: SVM Implementation\n",
    "- Loads data (either original CSV or pre-split X_train/X_test files if available)\n",
    "- Encodes categorical variables (one-hot)\n",
    "- Standardizes features\n",
    "- Trains SVM with small hyperparameter search\n",
    "- Evaluates and saves metrics, confusion matrix, and model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- User config ----------\n",
    "CSV_PATH = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\mushroom.csv\"\n",
    "OUTPUT_DIR = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\correlation_outputs\"\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "USE_PRE_SPLIT = False  # If True, we'll load X_train/X_test CSVs if available\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06d0e9e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8ecccb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # If pre-split files exist and user chose to use them, load those\n",
    "    if USE_PRE_SPLIT:\n",
    "        p = Path(CSV_PATH).parent\n",
    "        xtrain = p / \"X_train.csv\"\n",
    "        xtest = p / \"X_test.csv\"\n",
    "        ytrain = p / \"y_train.csv\"\n",
    "        ytest = p / \"y_test.csv\"\n",
    "        if xtrain.exists() and xtest.exists() and ytrain.exists() and ytest.exists():\n",
    "            X_train = pd.read_csv(xtrain)\n",
    "            X_test = pd.read_csv(xtest)\n",
    "            y_train = pd.read_csv(ytrain).iloc[:, 0].values\n",
    "            y_test = pd.read_csv(ytest).iloc[:, 0].values\n",
    "            print(\"Loaded pre-split X_train/X_test/y_train/y_test from folder.\")\n",
    "            return X_train, X_test, y_train, y_test\n",
    "        else:\n",
    "            print(\"Pre-split files requested but not found; falling back to single CSV load.\")\n",
    "\n",
    "    # Load full CSV, encode, and split\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    if 'class' not in df.columns:\n",
    "        raise SystemExit(\"Target column 'class' not found in CSV.\")\n",
    "\n",
    "    y = df['class'].copy()\n",
    "    X = df.drop(columns=['class'])\n",
    "\n",
    "    # Label encode target (assuming 'e'/'p' or 'edible'/'poisonous')\n",
    "    # Convert to 0/1\n",
    "    y = y.astype(str)\n",
    "    if set(y.unique()) <= set(['e', 'p']):\n",
    "        y_encoded = (y == 'p').astype(int).values  # poisonous=1, edible=0\n",
    "    else:\n",
    "        # fallback: map unique values to 0/1 by sorted order\n",
    "        unique = sorted(y.unique())\n",
    "        mapping = {unique[0]: 0, unique[1]: 1}\n",
    "        y_encoded = y.map(mapping).values\n",
    "        print(\"Target mapping used:\", mapping)\n",
    "\n",
    "    # One-hot encode features (drop_first=False to preserve full info; scaler handles multicollinearity)\n",
    "    X_encoded = pd.get_dummies(X, drop_first=False)\n",
    "    print(\"Feature matrix after one-hot encoding shape:\", X_encoded.shape)\n",
    "\n",
    "    # train-test split with stratify\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_encoded, y_encoded, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_encoded\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f3b34",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
    "    # Build pipeline: scaler + SVM\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(probability=False))\n",
    "    ])\n",
    "\n",
    "    # Small grid for C and kernel (keeps run-time reasonable)\n",
    "    param_grid = {\n",
    "        \"svc__C\": [0.1, 1, 5],\n",
    "        \"svc__kernel\": [\"rbf\", \"linear\"],\n",
    "        \"svc__gamma\": [\"scale\"]  # keep default gamma\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(pipe, param_grid, cv=3, scoring='f1', n_jobs=-1, verbose=1)\n",
    "    print(\"Starting GridSearchCV for SVM (this may take a bit)...\")\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best = grid.best_estimator_\n",
    "    print(\"Best params:\", grid.best_params_)\n",
    "    # Predict\n",
    "    y_pred = best.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    cls_report = classification_report(y_test, y_pred, digits=4, zero_division=0)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    results = {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1_score\": f1,\n",
    "        \"classification_report\": cls_report,\n",
    "        \"confusion_matrix\": cm.tolist()  # convert to list for easy saving\n",
    "    }\n",
    "\n",
    "    # Save model\n",
    "    model_path = os.path.join(OUTPUT_DIR, \"svm_best_model.joblib\")\n",
    "    joblib.dump(grid.best_estimator_, model_path)\n",
    "    print(f\"Saved trained model to: {model_path}\")\n",
    "\n",
    "    # Save results\n",
    "    results_df = pd.DataFrame({\n",
    "        \"metric\": [\"accuracy\", \"precision\", \"recall\", \"f1_score\"],\n",
    "        \"value\": [acc, prec, rec, f1]\n",
    "    })\n",
    "    results_df.to_csv(os.path.join(OUTPUT_DIR, \"svm_metrics_summary.csv\"), index=False)\n",
    "    with open(os.path.join(OUTPUT_DIR, \"svm_classification_report.txt\"), \"w\") as f:\n",
    "        f.write(cls_report)\n",
    "    pd.DataFrame(cm, index=[\"actual_0\",\"actual_1\"], columns=[\"pred_0\",\"pred_1\"]).to_csv(\n",
    "        os.path.join(OUTPUT_DIR, \"svm_confusion_matrix.csv\")\n",
    "    )\n",
    "    print(\"Saved metrics and confusion matrix to output folder.\")\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\n--- SVM Evaluation Summary ---\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"F1-score : {f1:.4f}\")\n",
    "    print(\"\\nClassification report:\\n\", cls_report)\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "    return results, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2774c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    X_train, X_test, y_train, y_test = load_data()\n",
    "    results, best_params = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "    print(\"\\nALL DONE â€” outputs in:\", OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
