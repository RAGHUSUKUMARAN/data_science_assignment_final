{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "553425dc",
   "metadata": {},
   "source": [
    "Step 1: Load and Explore the Mushroom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ac93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169fbea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\mushroom.csv\"\n",
    "mushroom_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed0722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic exploration\n",
    "print(\"Dataset shape:\", mushroom_df.shape)\n",
    "print(\"\\nColumn names:\\n\", list(mushroom_df.columns))\n",
    "print(\"\\nData types:\\n\", mushroom_df.dtypes)\n",
    "print(\"\\nMissing values per column:\\n\", mushroom_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview dataset\n",
    "print(\"\\nFirst 5 rows:\\n\", mushroom_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea026cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive summary (includes both numeric and categorical)\n",
    "print(\"\\nSummary statistics:\\n\", mushroom_df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5d0ac9",
   "metadata": {},
   "source": [
    "Step 2: Visualizing Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ed917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e82f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Categorical Features ---\n",
    "cat_features = ['cap_shape', 'cap_surface', 'cap_color', 'odor', 'habitat', 'class']\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(cat_features, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.countplot(x=feature, data=mushroom_df, palette='viridis')\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bff90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Numerical Features ---\n",
    "num_features = ['stalk_height', 'cap_diameter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e15d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms\n",
    "plt.figure(figsize=(12, 5))\n",
    "for i, feature in enumerate(num_features, 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    sns.histplot(mushroom_df[feature], kde=True, color='teal')\n",
    "    plt.title(f'{feature} Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots\n",
    "plt.figure(figsize=(12, 5))\n",
    "for i, feature in enumerate(num_features, 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    sns.boxplot(x=mushroom_df[feature], color='orange')\n",
    "    plt.title(f'Boxplot of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b2922",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feature_correlations.py\n",
    "Full pipeline to investigate feature correlations (robust loader + debug prints).\n",
    "Drop this file into your project and run with your venv python.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa681afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency, pointbiserialr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70805d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style=\"whitegrid\", font_scale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1071f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- User config ----------\n",
    "CSV_PATH = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\mushroom.csv\"\n",
    "TARGET_COL = None\n",
    "OUTPUT_DIR = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\correlation_outputs\"\n",
    "DROP_THRESHOLD_NUNIQUE = 1\n",
    "FILLNA_STRATEGY = \"mode\"\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cdf613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick sanity checks\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"CSV_PATH (raw):\", CSV_PATH)\n",
    "print(\"CSV_PATH (absolute):\", os.path.abspath(CSV_PATH))\n",
    "print(\"CSV_PATH exists?\", os.path.exists(CSV_PATH))\n",
    "print(\"Readable by current user?\", os.access(os.path.abspath(CSV_PATH), os.R_OK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176da800",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31b6d3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ---------- Robust load ----------\n",
    "def try_read_csv(path):\n",
    "    \"\"\"Try several common encodings/separators and return (df, used_params) or raise.\"\"\"\n",
    "    attempts = [\n",
    "        {\"sep\": \",\", \"encoding\": \"utf-8\"},\n",
    "        {\"sep\": \",\", \"encoding\": \"latin1\"},\n",
    "        {\"sep\": \";\", \"encoding\": \"utf-8\"},\n",
    "        {\"sep\": \"\\t\", \"encoding\": \"utf-8\"},\n",
    "    ]\n",
    "    last_exc = None\n",
    "    for params in attempts:\n",
    "        try:\n",
    "            df = pd.read_csv(path, **params)\n",
    "            return df, params\n",
    "        except Exception as e:\n",
    "            last_exc = e\n",
    "    # final fallback: let pandas infer with engine python (slower but forgiving)\n",
    "    try:\n",
    "        df = pd.read_csv(path, engine=\"python\")\n",
    "        return df, {\"engine\": \"python\"}\n",
    "    except Exception as e:\n",
    "        raise last_exc or e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a686b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If user provided a DataFrame in the environment (rare here), use that\n",
    "df = globals().get(\"mushroom_df\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a90bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is None:\n",
    "    if not os.path.exists(CSV_PATH):\n",
    "        sys.exit(f\"File not found: {os.path.abspath(CSV_PATH)}\\nCheck path, spelling, and that the drive is accessible.\")\n",
    "    try:\n",
    "        df, used = try_read_csv(CSV_PATH)\n",
    "        print(\"Loaded CSV successfully with params:\", used)\n",
    "    except PermissionError as pe:\n",
    "        sys.exit(f\"Permission error reading file: {pe}\\nCheck file permissions.\")\n",
    "    except Exception as e:\n",
    "        # show full info to help debugging\n",
    "        import traceback\n",
    "        tb = traceback.format_exc()\n",
    "        sys.exit(f\"Failed to read CSV. Last exception:\\n{e}\\n\\nTraceback:\\n{tb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15579748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic confirmation\n",
    "print(\"Dataframe shape:\", getattr(df, \"shape\", None))\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head().to_string(index=False))\n",
    "print(\"\\nDataFrame info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa9ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Basic cleaning ----------\n",
    "try:\n",
    "    nunique = df.nunique(dropna=True)\n",
    "    const_cols = list(nunique[nunique <= DROP_THRESHOLD_NUNIQUE].index)\n",
    "    if const_cols:\n",
    "        print(f\"Dropping constant / low-variance columns: {const_cols}\")\n",
    "        df = df.drop(columns=const_cols)\n",
    "except Exception as e:\n",
    "    print(\"Warning during dropping constant columns:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f1dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NAs simply (user can adjust)\n",
    "if FILLNA_STRATEGY == \"mode\":\n",
    "    for c in df.columns:\n",
    "        if df[c].isna().any():\n",
    "            try:\n",
    "                df[c].fillna(df[c].mode().iloc[0], inplace=True)\n",
    "            except Exception:\n",
    "                df[c].fillna(method=\"ffill\", inplace=True)\n",
    "elif FILLNA_STRATEGY == \"median\":\n",
    "    for c in df.select_dtypes(include=[np.number]).columns:\n",
    "        if df[c].isna().any():\n",
    "            df[c].fillna(df[c].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81bbc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic dtype coercion for mostly-numeric object columns\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        coerced = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        if coerced.notna().sum() / len(coerced) > 0.6:\n",
    "            df[col] = coerced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c48ccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Split numeric & categorical ----------\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bcfc14",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(f\"\\nNumeric columns ({len(num_cols)}): {num_cols}\")\n",
    "print(f\"Categorical columns ({len(cat_cols)}): {cat_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7619935a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ---------- Helpers ----------\n",
    "def savefig_and_show(fig, fname):\n",
    "    path = os.path.join(OUTPUT_DIR, fname)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=150)\n",
    "    print(f\"Saved figure to {path}\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb01b1ca",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def cramers_v(series_x, series_y):\n",
    "    confusion = pd.crosstab(series_x, series_y)\n",
    "    if confusion.size == 0:\n",
    "        return np.nan\n",
    "    chi2, p, dof, expected = chi2_contingency(confusion)\n",
    "    n = confusion.sum().sum()\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion.shape\n",
    "    phi2corr = max(0, phi2 - ((k - 1)*(r - 1)) / (n - 1))\n",
    "    rcorr = r - ((r - 1)**2) / (n - 1)\n",
    "    kcorr = k - ((k - 1)**2) / (n - 1)\n",
    "    denom = min(kcorr - 1, rcorr - 1)\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    return np.sqrt(phi2corr / denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cee7be",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def correlation_ratio(categories, measurements):\n",
    "    categories = pd.Series(categories)\n",
    "    measurements = pd.Series(measurements)\n",
    "    mask = categories.notna() & measurements.notna()\n",
    "    categories = categories[mask]\n",
    "    measurements = measurements[mask]\n",
    "    if len(measurements) == 0:\n",
    "        return np.nan\n",
    "    cat_groups = measurements.groupby(categories)\n",
    "    mean_total = measurements.mean()\n",
    "    ss_between = sum([(grp.size * (grp.mean() - mean_total)**2) for _, grp in cat_groups])\n",
    "    ss_total = ((measurements - mean_total)**2).sum()\n",
    "    if ss_total == 0:\n",
    "        return 0.0\n",
    "    return np.sqrt(ss_between / ss_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Numeric correlations ----------\n",
    "if num_cols:\n",
    "    pearson = df[num_cols].corr(method=\"pearson\")\n",
    "    spearman = df[num_cols].corr(method=\"spearman\")\n",
    "    pearson.to_csv(os.path.join(OUTPUT_DIR, \"pearson_correlation_matrix.csv\"))\n",
    "    spearman.to_csv(os.path.join(OUTPUT_DIR, \"spearman_correlation_matrix.csv\"))\n",
    "    print(\"Saved numeric correlation matrices (pearson, spearman).\")\n",
    "    fig, ax = plt.subplots(figsize=(max(6, len(num_cols)*0.5), max(4, len(num_cols)*0.5)))\n",
    "    sns.heatmap(pearson, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=False,\n",
    "                cbar_kws={'shrink': .6}, linewidths=.5)\n",
    "    ax.set_title(\"Pearson Correlation (Numeric features)\")\n",
    "    savefig_and_show(fig, \"pearson_heatmap.png\")\n",
    "    pairs = []\n",
    "    for a, b in combinations(num_cols, 2):\n",
    "        pairs.append((a, b, pearson.loc[a, b]))\n",
    "    top_abs = sorted(pairs, key=lambda x: -abs(x[2]))[:20]\n",
    "    top_df = pd.DataFrame(top_abs, columns=[\"feature_a\", \"feature_b\", \"pearson_corr\"])\n",
    "    top_df.to_csv(os.path.join(OUTPUT_DIR, \"top_numeric_pairs_by_abs_pearson.csv\"), index=False)\n",
    "    print(\"Saved top numeric correlated pairs.\")\n",
    "else:\n",
    "    print(\"No numeric columns found; skipping numeric correlation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Categorical vs Categorical (Cramér's V) ----------\n",
    "if len(cat_cols) >= 2:\n",
    "    cramers_matrix = pd.DataFrame(index=cat_cols, columns=cat_cols, dtype=float)\n",
    "    for a, b in combinations(cat_cols, 2):\n",
    "        v = cramers_v(df[a], df[b])\n",
    "        cramers_matrix.loc[a, b] = v\n",
    "        cramers_matrix.loc[b, a] = v\n",
    "    np.fill_diagonal(cramers_matrix.values, 1.0)\n",
    "    cramers_matrix = cramers_matrix.fillna(0.0).astype(float)\n",
    "    cramers_matrix.to_csv(os.path.join(OUTPUT_DIR, \"cramers_v_matrix.csv\"))\n",
    "    print(\"Saved Cramér's V matrix for categorical features.\")\n",
    "    fig, ax = plt.subplots(figsize=(max(6, len(cat_cols)*0.35), max(6, len(cat_cols)*0.35)))\n",
    "    sns.heatmap(cramers_matrix, annot=True, fmt=\".2f\", cmap=\"vlag\", linewidths=.3)\n",
    "\n",
    "    ax.set_title(\"Cramér's V (Categorical vs Categorical)\")\n",
    "    savefig_and_show(fig, \"cramers_v_heatmap.png\")\n",
    "    cat_pairs = []\n",
    "    for a, b in combinations(cat_cols, 2):\n",
    "        cat_pairs.append((a, b, cramers_matrix.loc[a, b]))\n",
    "    top_cat = sorted(cat_pairs, key=lambda x: -x[2])[:30]\n",
    "    pd.DataFrame(top_cat, columns=[\"cat_a\", \"cat_b\", \"cramers_v\"]).to_csv(\n",
    "        os.path.join(OUTPUT_DIR, \"top_categorical_pairs_by_cramers.csv\"), index=False)\n",
    "    print(\"Saved top categorical pairs by Cramér's V.\")\n",
    "else:\n",
    "    print(\"Not enough categorical columns for Cramér's V (need >=2).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Categorical -> Numeric (Correlation ratio) ----------\n",
    "if cat_cols and num_cols:\n",
    "    eta_matrix = pd.DataFrame(index=cat_cols, columns=num_cols, dtype=float)\n",
    "    for c in cat_cols:\n",
    "        for n in num_cols:\n",
    "            eta_matrix.loc[c, n] = correlation_ratio(df[c], df[n])\n",
    "    eta_matrix = eta_matrix.fillna(0.0).astype(float)\n",
    "    eta_matrix.to_csv(os.path.join(OUTPUT_DIR, \"eta_correlation_ratio_matrix.csv\"))\n",
    "    print(\"Saved correlation ratio (eta) matrix for categorical->numeric.\")\n",
    "    fig, ax = plt.subplots(figsize=(max(6, len(num_cols)*0.5), max(4, len(cat_cols)*0.25)))\n",
    "    sns.heatmap(eta_matrix, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", linewidths=.3)\n",
    "    ax.set_title(\"Correlation Ratio (categorical -> numeric) η\")\n",
    "    savefig_and_show(fig, \"eta_heatmap.png\")\n",
    "    top_eta_rows = []\n",
    "    for c in cat_cols:\n",
    "        row = eta_matrix.loc[c].sort_values(ascending=False)[:10]\n",
    "        for n, val in row.items():\n",
    "            top_eta_rows.append((c, n, val))\n",
    "    pd.DataFrame(top_eta_rows, columns=[\"categorical\", \"numeric\", \"eta\"]).to_csv(\n",
    "        os.path.join(OUTPUT_DIR, \"top_categorical_to_numeric_eta.csv\"), index=False)\n",
    "    print(\"Saved categorical -> numeric top explanations (eta).\")\n",
    "else:\n",
    "    print(\"Skipping categorical->numeric eta matrix (need both categorical and numeric columns).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fbb3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Extra: numeric vs binary categorical using point-biserial (if present) ----------\n",
    "binary_cat = [c for c in cat_cols if df[c].nunique() == 2]\n",
    "if binary_cat and num_cols:\n",
    "    pb_list = []\n",
    "    for c in binary_cat:\n",
    "        values = pd.Categorical(df[c]).codes\n",
    "        for n in num_cols:\n",
    "            try:\n",
    "                r, p = pointbiserialr(values, df[n])\n",
    "                pb_list.append((c, n, r, p))\n",
    "            except Exception:\n",
    "                pb_list.append((c, n, np.nan, np.nan))\n",
    "    pb_df = pd.DataFrame(pb_list, columns=[\"binary_cat\", \"numeric\", \"pointbiserial_r\", \"p_value\"])\n",
    "    pb_df.to_csv(os.path.join(OUTPUT_DIR, \"pointbiserial_binary_cat_numeric.csv\"), index=False)\n",
    "    print(\"Saved point-biserial correlations for binary categorical features.\")\n",
    "else:\n",
    "    print(\"No binary categorical columns or no numeric columns found; skipping point-biserial step.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b5d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Summary output: top correlations consolidated ----------\n",
    "summary_rows = []\n",
    "if num_cols:\n",
    "    for _, r in top_df.iterrows():\n",
    "        summary_rows.append({\n",
    "            \"type\": \"numeric-numeric\",\n",
    "            \"a\": r['feature_a'],\n",
    "            \"b\": r['feature_b'],\n",
    "            \"score\": r['pearson_corr']\n",
    "        })\n",
    "if len(cat_cols) >= 2:\n",
    "    for row in top_cat:\n",
    "        summary_rows.append({\n",
    "            \"type\": \"cat-cat\",\n",
    "            \"a\": row[0],\n",
    "            \"b\": row[1],\n",
    "            \"score\": row[2]\n",
    "        })\n",
    "if cat_cols and num_cols:\n",
    "    for c, n, val in top_eta_rows:\n",
    "        summary_rows.append({\n",
    "            \"type\": \"cat->num\",\n",
    "            \"a\": c,\n",
    "            \"b\": n,\n",
    "            \"score\": val\n",
    "        })\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(by=\"score\", key=lambda col: col.abs(), ascending=False)\n",
    "summary_df.to_csv(os.path.join(OUTPUT_DIR, \"consolidated_top_correlations.csv\"), index=False)\n",
    "print(f\"Saved consolidated top correlations to {os.path.join(OUTPUT_DIR, 'consolidated_top_correlations.csv')}\")\n",
    "print(\"\\nDONE — All outputs are in the folder:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d3e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2_preprocessing.py\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79093ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the encoded dataset\n",
    "file_path = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\mushroom.csv\"\n",
    "mushroom_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19798cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display shape and first few rows\n",
    "print(\"Initial dataset shape:\", mushroom_df.shape)\n",
    "print(mushroom_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1733ae54",
   "metadata": {},
   "source": [
    "--- Step 1: Encode Categorical Variables ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463eb974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = mushroom_df.drop('class', axis=1)\n",
    "y = mushroom_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88237a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target label (edible/poisonous)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec29523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding for categorical predictors\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eff406",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After encoding:\")\n",
    "print(\"Feature matrix shape:\", X_encoded.shape)\n",
    "print(\"Target vector shape:\", y_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b263b6",
   "metadata": {},
   "source": [
    "--- Step 2: Split Dataset ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4255289",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a5fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527e8b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save preprocessed data ---\n",
    "X_train.to_csv(r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\X_train.csv\", index=False)\n",
    "X_test.to_csv(r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\X_test.csv\", index=False)\n",
    "pd.DataFrame(y_train, columns=['class']).to_csv(r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\y_train.csv\", index=False)\n",
    "pd.DataFrame(y_test, columns=['class']).to_csv(r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a3c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preprocessing complete. Encoded and split data saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3_visualization.py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f0d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\mushroom.csv\"\n",
    "mushroom_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af41ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85775fe5",
   "metadata": {},
   "source": [
    "--- Step 1: Feature Distributions and Relationships ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b57e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct column names for UCI Mushroom dataset\n",
    "selected_features = ['odor', 'spore_print_color', 'gill_color', 'cap_color', 'habitat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f2552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check for columns\n",
    "print(\"Columns in dataset:\", mushroom_df.columns.tolist())\n",
    "for feature in selected_features:\n",
    "    if feature not in mushroom_df.columns:\n",
    "        print(f\"⚠️ Warning: Column '{feature}' not found in dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28f1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "for i, feature in enumerate(selected_features, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.countplot(x=feature, hue='class', data=mushroom_df)\n",
    "    plt.title(f\"Distribution of {feature} by Class\")\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\feature_distributions.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dbb6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Class Distribution Visualization ---\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.countplot(x='class', data=mushroom_df, palette='Set1')\n",
    "plt.title(\"Class Distribution (Edible vs. Poisonous)\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.savefig(r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\class_distribution.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84110f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "step4_svm.py\n",
    "Task 4: SVM Implementation\n",
    "- Loads data (either original CSV or pre-split X_train/X_test files if available)\n",
    "- Encodes categorical variables (one-hot)\n",
    "- Standardizes features\n",
    "- Trains SVM with small hyperparameter search\n",
    "- Evaluates and saves metrics, confusion matrix, and model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- User config ----------\n",
    "CSV_PATH = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\mushroom.csv\"\n",
    "OUTPUT_DIR = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\correlation_outputs\"\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "USE_PRE_SPLIT = False  # If True, we'll load X_train/X_test CSVs if available\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06d0e9e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8ecccb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # If pre-split files exist and user chose to use them, load those\n",
    "    if USE_PRE_SPLIT:\n",
    "        p = Path(CSV_PATH).parent\n",
    "        xtrain = p / \"X_train.csv\"\n",
    "        xtest = p / \"X_test.csv\"\n",
    "        ytrain = p / \"y_train.csv\"\n",
    "        ytest = p / \"y_test.csv\"\n",
    "        if xtrain.exists() and xtest.exists() and ytrain.exists() and ytest.exists():\n",
    "            X_train = pd.read_csv(xtrain)\n",
    "            X_test = pd.read_csv(xtest)\n",
    "            y_train = pd.read_csv(ytrain).iloc[:, 0].values\n",
    "            y_test = pd.read_csv(ytest).iloc[:, 0].values\n",
    "            print(\"Loaded pre-split X_train/X_test/y_train/y_test from folder.\")\n",
    "            return X_train, X_test, y_train, y_test\n",
    "        else:\n",
    "            print(\"Pre-split files requested but not found; falling back to single CSV load.\")\n",
    "\n",
    "    # Load full CSV, encode, and split\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    if 'class' not in df.columns:\n",
    "        raise SystemExit(\"Target column 'class' not found in CSV.\")\n",
    "\n",
    "    y = df['class'].copy()\n",
    "    X = df.drop(columns=['class'])\n",
    "\n",
    "    # Label encode target (assuming 'e'/'p' or 'edible'/'poisonous')\n",
    "    # Convert to 0/1\n",
    "    y = y.astype(str)\n",
    "    if set(y.unique()) <= set(['e', 'p']):\n",
    "        y_encoded = (y == 'p').astype(int).values  # poisonous=1, edible=0\n",
    "    else:\n",
    "        # fallback: map unique values to 0/1 by sorted order\n",
    "        unique = sorted(y.unique())\n",
    "        mapping = {unique[0]: 0, unique[1]: 1}\n",
    "        y_encoded = y.map(mapping).values\n",
    "        print(\"Target mapping used:\", mapping)\n",
    "\n",
    "    # One-hot encode features (drop_first=False to preserve full info; scaler handles multicollinearity)\n",
    "    X_encoded = pd.get_dummies(X, drop_first=False)\n",
    "    print(\"Feature matrix after one-hot encoding shape:\", X_encoded.shape)\n",
    "\n",
    "    # train-test split with stratify\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_encoded, y_encoded, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_encoded\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f3b34",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
    "    # Build pipeline: scaler + SVM\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(probability=False))\n",
    "    ])\n",
    "\n",
    "    # Small grid for C and kernel (keeps run-time reasonable)\n",
    "    param_grid = {\n",
    "        \"svc__C\": [0.1, 1, 5],\n",
    "        \"svc__kernel\": [\"rbf\", \"linear\"],\n",
    "        \"svc__gamma\": [\"scale\"]  # keep default gamma\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(pipe, param_grid, cv=3, scoring='f1', n_jobs=-1, verbose=1)\n",
    "    print(\"Starting GridSearchCV for SVM (this may take a bit)...\")\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best = grid.best_estimator_\n",
    "    print(\"Best params:\", grid.best_params_)\n",
    "    # Predict\n",
    "    y_pred = best.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    cls_report = classification_report(y_test, y_pred, digits=4, zero_division=0)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    results = {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1_score\": f1,\n",
    "        \"classification_report\": cls_report,\n",
    "        \"confusion_matrix\": cm.tolist()  # convert to list for easy saving\n",
    "    }\n",
    "\n",
    "    # Save model\n",
    "    model_path = os.path.join(OUTPUT_DIR, \"svm_best_model.joblib\")\n",
    "    joblib.dump(grid.best_estimator_, model_path)\n",
    "    print(f\"Saved trained model to: {model_path}\")\n",
    "\n",
    "    # Save results\n",
    "    results_df = pd.DataFrame({\n",
    "        \"metric\": [\"accuracy\", \"precision\", \"recall\", \"f1_score\"],\n",
    "        \"value\": [acc, prec, rec, f1]\n",
    "    })\n",
    "    results_df.to_csv(os.path.join(OUTPUT_DIR, \"svm_metrics_summary.csv\"), index=False)\n",
    "    with open(os.path.join(OUTPUT_DIR, \"svm_classification_report.txt\"), \"w\") as f:\n",
    "        f.write(cls_report)\n",
    "    pd.DataFrame(cm, index=[\"actual_0\",\"actual_1\"], columns=[\"pred_0\",\"pred_1\"]).to_csv(\n",
    "        os.path.join(OUTPUT_DIR, \"svm_confusion_matrix.csv\")\n",
    "    )\n",
    "    print(\"Saved metrics and confusion matrix to output folder.\")\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\n--- SVM Evaluation Summary ---\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"F1-score : {f1:.4f}\")\n",
    "    print(\"\\nClassification report:\\n\", cls_report)\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "    return results, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2774c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    X_train, X_test, y_train, y_test = load_data()\n",
    "    results, best_params = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "    print(\"\\nALL DONE — outputs in:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c3e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step5_visualize_results.py\n",
    "\"\"\"\n",
    "Visualize SVM classification results.\n",
    "Saves plots to OUTPUT_DIR.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57187762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_curve, auc, RocCurveDisplay\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ea88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- User config ----------\n",
    "OUTPUT_DIR = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\correlation_outputs\"\n",
    "MODEL_PATH = os.path.join(OUTPUT_DIR, \"svm_best_model.joblib\")\n",
    "CSV_PATH = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\17 SVM\\SVM\\mushroom.csv\"  # fallback if pre-split not used\n",
    "USE_PRE_SPLIT = False  # if you saved X_test/y_test CSVs set True and script will try to load them\n",
    "PLOT_DPI = 150\n",
    "RANDOM_STATE = 42\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4bc2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd85ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Load model and data ----------\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    raise SystemExit(f\"Model not found at {MODEL_PATH}. Run Task 4 to save svm_best_model.joblib first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ca7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(MODEL_PATH)\n",
    "print(\"Loaded model:\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1680a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data (prefer pre-split files if available)\n",
    "if USE_PRE_SPLIT:\n",
    "    base = os.path.dirname(CSV_PATH)\n",
    "    x_test_path = os.path.join(base, \"X_test.csv\")\n",
    "    y_test_path = os.path.join(base, \"y_test.csv\")\n",
    "    if os.path.exists(x_test_path) and os.path.exists(y_test_path):\n",
    "        X_test = pd.read_csv(x_test_path)\n",
    "        y_test = pd.read_csv(y_test_path).iloc[:, 0].values\n",
    "    else:\n",
    "        raise SystemExit(\"Pre-split test files requested but not found.\")\n",
    "else:\n",
    "    # load full CSV and split here to reproduce same split as Task 4\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    if 'class' not in df.columns:\n",
    "        raise SystemExit(\"Target column 'class' not found in CSV.\")\n",
    "    y = df['class'].astype(str)\n",
    "    X = df.drop(columns=['class'])\n",
    "    # encode y to 0/1 same logic as training script\n",
    "    if set(y.unique()) <= set(['e', 'p']):\n",
    "        y_encoded = (y == 'p').astype(int).values\n",
    "    else:\n",
    "        unique = sorted(y.unique())\n",
    "        mapping = {unique[0]: 0, unique[1]: 1}\n",
    "        y_encoded = y.map(mapping).values\n",
    "    X_encoded = pd.get_dummies(X, drop_first=False)\n",
    "    # ensure columns line up (if training used same encoding)\n",
    "    # If model was trained on a different feature set, prefer using saved pre-split CSVs.\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_encoded, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cc85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "X_test_arr = np.asarray(X_test)\n",
    "y_test_arr = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610e8f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Predictions ----------\n",
    "y_pred = model.predict(X_test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48798f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_arr, y_pred)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9855881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save confusion matrix (counts)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=[\"pred_0\",\"pred_1\"], yticklabels=[\"true_0\",\"true_1\"])\n",
    "plt.ylabel(\"True\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix (counts)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"svm_confusion_matrix_counts.png\"), dpi=PLOT_DPI)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7963969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save normalized confusion matrix (percent)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues', cbar=False,\n",
    "            xticklabels=[\"pred_0\",\"pred_1\"], yticklabels=[\"true_0\",\"true_1\"])\n",
    "plt.ylabel(\"True\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix (normalized)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"svm_confusion_matrix_normalized.png\"), dpi=PLOT_DPI)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b550c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report heatmap (turn report into a dataframe)\n",
    "report = classification_report(y_test_arr, y_pred, output_dict=True, zero_division=0)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "# Save textual report\n",
    "with open(os.path.join(OUTPUT_DIR, \"svm_classification_report.txt\"), \"w\") as f:\n",
    "    f.write(classification_report(y_test_arr, y_pred, zero_division=0))\n",
    "report_df.to_csv(os.path.join(OUTPUT_DIR, \"svm_classification_report_table.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48612f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot classification report (precision, recall, f1) for classes\n",
    "metrics_df = report_df.loc[['0','1'], ['precision','recall','f1-score']].astype(float)\n",
    "plt.figure(figsize=(6,4))\n",
    "metrics_df.plot(kind='bar')\n",
    "plt.title(\"Precision / Recall / F1-score by Class\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"svm_class_metrics_bar.png\"), dpi=PLOT_DPI)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0c937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- ROC curve & AUC ----------\n",
    "y_score = None\n",
    "if hasattr(model, \"decision_function\"):\n",
    "    try:\n",
    "        y_score = model.decision_function(X_test_arr)\n",
    "    except Exception:\n",
    "        y_score = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c470b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_score is None and hasattr(model, \"predict_proba\"):\n",
    "    try:\n",
    "        y_score = model.predict_proba(X_test_arr)[:, 1]\n",
    "    except Exception:\n",
    "        y_score = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0562a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_score is not None:\n",
    "    fpr, tpr, _ = roc_curve(y_test_arr, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'AUC = {roc_auc:.4f}')\n",
    "    plt.plot([0,1], [0,1], linestyle='--', color='gray', linewidth=1)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"svm_roc_auc.png\"), dpi=PLOT_DPI)\n",
    "    plt.close()\n",
    "    print(\"Saved ROC curve. AUC:\", roc_auc)\n",
    "else:\n",
    "    print(\"Model does not expose decision_function or predict_proba. ROC curve skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe7d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 2D Embeddings (PCA and t-SNE) colored by true/predicted ----------\n",
    "# PCA (fast)\n",
    "pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "try:\n",
    "    X_2d_pca = pca.fit_transform(X_test_arr)\n",
    "    df_plot = pd.DataFrame({\n",
    "        'pc1': X_2d_pca[:,0],\n",
    "        'pc2': X_2d_pca[:,1],\n",
    "        'true': y_test_arr,\n",
    "        'pred': y_pred\n",
    "    })\n",
    "    # True labels\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.scatterplot(data=df_plot, x='pc1', y='pc2', hue='true', style='true', s=40, palette='deep')\n",
    "    plt.title('PCA 2D - True labels')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"svm_pca_true_labels.png\"), dpi=PLOT_DPI)\n",
    "    plt.close()\n",
    "\n",
    "    # Predicted labels\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.scatterplot(data=df_plot, x='pc1', y='pc2', hue='pred', style='pred', s=40, palette='deep')\n",
    "    plt.title('PCA 2D - Predicted labels')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"svm_pca_pred_labels.png\"), dpi=PLOT_DPI)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(\"PCA embedding failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78295363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE (slower; sample if too big)\n",
    "tsne_n = min(2000, X_test_arr.shape[0])  # cap samples for speed\n",
    "if X_test_arr.shape[0] > tsne_n:\n",
    "    sample_idx = np.random.RandomState(RANDOM_STATE).choice(X_test_arr.shape[0], size=tsne_n, replace=False)\n",
    "    X_sample = X_test_arr[sample_idx]\n",
    "    y_sample = y_test_arr[sample_idx]\n",
    "    y_pred_sample = y_pred[sample_idx]\n",
    "else:\n",
    "    X_sample = X_test_arr\n",
    "    y_sample = y_test_arr\n",
    "    y_pred_sample = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a585359",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tsne = TSNE(n_components=2, perplexity=30, random_state=RANDOM_STATE, init='pca')\n",
    "    X_2d_tsne = tsne.fit_transform(X_sample)\n",
    "    df_tsne = pd.DataFrame({\n",
    "        'tsne1': X_2d_tsne[:,0],\n",
    "        'tsne2': X_2d_tsne[:,1],\n",
    "        'true': y_sample,\n",
    "        'pred': y_pred_sample\n",
    "    })\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.scatterplot(data=df_tsne, x='tsne1', y='tsne2', hue='true', s=30, palette='tab10')\n",
    "    plt.title('t-SNE (true labels)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"svm_tsne_true_labels.png\"), dpi=PLOT_DPI)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.scatterplot(data=df_tsne, x='tsne1', y='tsne2', hue='pred', s=30, palette='tab10')\n",
    "    plt.title('t-SNE (predicted labels)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"svm_tsne_pred_labels.png\"), dpi=PLOT_DPI)\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(\"t-SNE embedding failed or too slow:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09398c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All visualizations saved to:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a120ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_tuning.py\n",
    "\"\"\"\n",
    "SVM hyperparameter tuning and evaluation script.\n",
    "\n",
    "Assumptions:\n",
    "- You have X (features) and y (labels). If not, uncomment the example using sklearn's iris dataset.\n",
    "- Recommended: run inside a virtualenv with scikit-learn installed (>=0.24).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b957641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold,\n",
    "    GridSearchCV, RandomizedSearchCV\n",
    ")\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c5da21",
   "metadata": {},
   "source": [
    "---------- USER DATA LOADING ----------\n",
    "Option A: if you already have X,y (numpy arrays or pandas)\n",
    "from your_data_module import X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30880df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option B: quick example dataset (uncomment to test script immediately)\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af466ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- TRAIN/TEST SPLIT ----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854efe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- COMMON PIPELINE ----------\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\", SVC(probability=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be64b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- CROSS-VALIDATION SETUP ----------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf743f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- PARAM GRID FOR GRIDSEARCH ----------\n",
    "# We separate grids by kernel to keep combinatorial explosion manageable.\n",
    "param_grid = [\n",
    "    {\n",
    "        \"svc__kernel\": [\"linear\"],\n",
    "        \"svc__C\": [0.01, 0.1, 1, 10, 100],\n",
    "        \"svc__class_weight\": [None, \"balanced\"],\n",
    "    },\n",
    "    {\n",
    "        \"svc__kernel\": [\"rbf\"],\n",
    "        \"svc__C\": [0.1, 1, 10, 100],\n",
    "        \"svc__gamma\": [\"scale\", \"auto\", 0.001, 0.01, 0.1, 1],\n",
    "        \"svc__class_weight\": [None, \"balanced\"],\n",
    "    },\n",
    "    {\n",
    "        \"svc__kernel\": [\"poly\"],\n",
    "        \"svc__C\": [0.1, 1, 10],\n",
    "        \"svc__degree\": [2, 3, 4],\n",
    "        \"svc__gamma\": [\"scale\", \"auto\"],\n",
    "        \"svc__coef0\": [0.0, 0.1, 0.5],\n",
    "        \"svc__class_weight\": [None],\n",
    "    },\n",
    "    {\n",
    "        \"svc__kernel\": [\"sigmoid\"],\n",
    "        \"svc__C\": [0.1, 1, 10],\n",
    "        \"svc__gamma\": [\"scale\", \"auto\", 0.01, 0.1],\n",
    "        \"svc__coef0\": [0.0, 0.1, 0.5],\n",
    "        \"svc__class_weight\": [None],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef4a55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- RANDOMIZED GRID (broader search) ----------\n",
    "# If you have many features / dataset large, randomized search is faster.\n",
    "param_dist = {\n",
    "    \"svc__kernel\": [\"rbf\", \"linear\", \"poly\", \"sigmoid\"],\n",
    "    \"svc__C\": [10**k for k in np.linspace(-3, 3, 11)],      # 1e-3 .. 1e3\n",
    "    \"svc__gamma\": [\"scale\", \"auto\"]+ [10**k for k in np.linspace(-4, 0, 5)], # mix\n",
    "    \"svc__degree\": [2, 3, 4],    # only relevant for poly\n",
    "    \"svc__coef0\": [0.0, 0.1, 0.5],\n",
    "    \"svc__class_weight\": [None, \"balanced\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fecfec3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Note: We defined param_dist above but RandomizedSearchCV will ignore keys that\n",
    "don't apply to a kernel (e.g., degree for non-poly). That's okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c043d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ---------- FUNCTIONS FOR TUNING & EVAL ----------\n",
    "def run_grid_search(pipe, param_grid, X_train, y_train, cv, scoring=\"f1_macro\", n_jobs=-1):\n",
    "    print(\"Starting GridSearchCV...\")\n",
    "    t0 = time.time()\n",
    "    grid = GridSearchCV(\n",
    "        pipe, param_grid, cv=cv, scoring=scoring,\n",
    "        verbose=2, n_jobs=n_jobs, refit=True\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"Grid search done in {elapsed:.1f} s\")\n",
    "    print(\"Best score (CV):\", grid.best_score_)\n",
    "    print(\"Best params:\", grid.best_params_)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d4595",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_random_search(pipe, param_dist, X_train, y_train, cv, n_iter=40, scoring=\"f1_macro\", n_jobs=-1):\n",
    "    print(\"Starting RandomizedSearchCV...\")\n",
    "    t0 = time.time()\n",
    "    rand = RandomizedSearchCV(\n",
    "        pipe, param_dist, n_iter=n_iter, cv=cv, scoring=scoring,\n",
    "        verbose=2, n_jobs=n_jobs, random_state=42, refit=True\n",
    "    )\n",
    "    rand.fit(X_train, y_train)\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"Randomized search done in {elapsed:.1f} s\")\n",
    "    print(\"Best score (CV):\", rand.best_score_)\n",
    "    print(\"Best params:\", rand.best_params_)\n",
    "    return rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe571ac1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, target_names=None, save_cm_fig=True, cm_filename=\"confusion_matrix.png\"):\n",
    "    print(\"\\n--- Test set evaluation ---\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp.plot(ax=ax, cmap=plt.cm.Blues, colorbar=False)\n",
    "    plt.title(\"Confusion Matrix (test set)\")\n",
    "    if save_cm_fig:\n",
    "        plt.savefig(cm_filename, bbox_inches=\"tight\")\n",
    "        print(f\"Saved confusion matrix to {cm_filename}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63153c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- RUN TUNING (pick one or both) ----------\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Quick Randomized Search (broad)\n",
    "    try:\n",
    "        rand_search = run_random_search(\n",
    "            pipe,\n",
    "            param_dist,\n",
    "            X_train, y_train,\n",
    "            cv=cv,\n",
    "            n_iter=30,      # reduce/increase based on compute budget\n",
    "            scoring=\"f1_macro\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Randomized search failed (likely due to param_dist construction).\")\n",
    "        print(e)\n",
    "        rand_search = None\n",
    "\n",
    "    # 2) More exhaustive Grid Search (fine-tuning)\n",
    "    grid_search = run_grid_search(\n",
    "        pipe,\n",
    "        param_grid,\n",
    "        X_train, y_train,\n",
    "        cv=cv,\n",
    "        scoring=\"f1_macro\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Pick best model (prefer grid_search best if available)\n",
    "    best_model = None\n",
    "    if grid_search is not None:\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(\"\\nSelected model from GridSearch.\")\n",
    "    elif rand_search is not None:\n",
    "        best_model = rand_search.best_estimator_\n",
    "        print(\"\\nSelected model from RandomizedSearch.\")\n",
    "    else:\n",
    "        raise RuntimeError(\"No tuned model available. Both searches failed.\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    class_names = [str(c) for c in np.unique(y)]\n",
    "    evaluate_model(best_model, X_test, y_test, target_names=class_names)\n",
    "\n",
    "    # Save best model\n",
    "    joblib.dump(best_model, \"best_svm_model.joblib\")\n",
    "    print(\"Saved best model to best_svm_model.joblib\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
