{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cdf04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: ARIMA modelling\n",
    "# Save as arima_part2.py or run in a Jupyter cell.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d32f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2675821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Load data ----------\n",
    "file_path = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\20 timeseries\\Timeseries\\exchange_rate.csv\"\n",
    "df = pd.read_csv(file_path, parse_dates=[0])\n",
    "df.columns = ['date', 'Ex_rate']   # ensure consistent names\n",
    "df = df.sort_values('date').set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e8874",
   "metadata": {},
   "source": [
    "If your data is more granular than monthly, and you want monthly frequency:\n",
    "df = df.asfreq('D')  # only if truly daily; else don't force frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5c3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Quick plot ----------\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(df.index, df['Ex_rate'], label='USD â†’ AUD')\n",
    "plt.title('USD to AUD Exchange Rate')\n",
    "plt.xlabel('Date'); plt.ylabel('Exchange Rate'); plt.grid(True); plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9104d04",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ---------- 1) Stationarity check (ADF test) ----------\n",
    "def adf_report(series, signif=0.05):\n",
    "    res = adfuller(series.dropna(), autolag='AIC')\n",
    "    output = {\n",
    "        'adf_stat': res[0],\n",
    "        'p_value': res[1],\n",
    "        'n_lags': res[2],\n",
    "        'n_obs': res[3],\n",
    "        'crit_vals': res[4]\n",
    "    }\n",
    "    print(\"ADF Statistic: {:.6f}\".format(output['adf_stat']))\n",
    "    print(\"p-value: {:.6f}\".format(output['p_value']))\n",
    "    for k, v in output['crit_vals'].items():\n",
    "        print(\"Critical Value ({}): {:.6f}\".format(k, v))\n",
    "    if output['p_value'] < signif:\n",
    "        print(\"Conclusion: Reject H0 -> series is stationary (at {:.2%} significance).\".format(signif))\n",
    "    else:\n",
    "        print(\"Conclusion: Fail to reject H0 -> series is non-stationary (needs differencing).\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b305689",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"\\n== ADF test on original series ==\")\n",
    "adf_report(df['Ex_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5771275d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# If non-stationary, difference once and test again:\n",
    "df['diff1'] = df['Ex_rate'].diff()\n",
    "print(\"\\n== ADF test on first difference ==\")\n",
    "adf_report(df['diff1'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcba95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 2) ACF and PACF to choose p and q ----------\n",
    "# Plot the ACF and PACF for the (differenced) stationary series\n",
    "series_for_ac = df['diff1'].dropna() if adfuller(df['Ex_rate'].dropna())[1] > 0.05 else df['Ex_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc5901",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plot_acf(series_for_ac, lags=40, zero=False)\n",
    "plt.title('ACF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c3fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plot_pacf(series_for_ac, lags=40, method='ywm')  # use ywm or kubo; ywm is robust\n",
    "plt.title('PACF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcd461f",
   "metadata": {},
   "source": [
    "Based on ACF/PACF you pick p and q:\n",
    "- If PACF cuts off after lag k and ACF tails -> AR(p) with p=k\n",
    "- If ACF cuts off after lag k and PACF tails -> MA(q) with q=k\n",
    "- If both tail -> mixed ARMA\n",
    "We'll pick a few candidate models to try; common approach: try small p/q: 0-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b74850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 3) Train-test split ----------\n",
    "# We'll do a time-series split: last 12 months (or last 10% of samples) for testing\n",
    "n = len(df)\n",
    "test_size = int(0.10 * n)     # use 10% for test\n",
    "train, test = df['Ex_rate'][:-test_size], df['Ex_rate'][-test_size:]\n",
    "print(f\"\\nUsing {len(train)} points for training and {len(test)} for testing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff11377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 4) Fit ARIMA models (try several small combinations) ----------\n",
    "candidate_orders = [(1,1,0), (0,1,1), (1,1,1), (2,1,1), (2,1,0), (0,1,2)]\n",
    "fitted_models = {}\n",
    "for order in candidate_orders:\n",
    "    try:\n",
    "        m = ARIMA(train, order=order)\n",
    "        res = m.fit()\n",
    "        fitted_models[order] = res\n",
    "        print(f\"Fitted ARIMA{order}   AIC: {res.aic:.2f}   BIC: {res.bic:.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ARIMA{order} failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65541903",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Choose best by AIC\n",
    "best_order = min(fitted_models.keys(), key=lambda o: fitted_models[o].aic)\n",
    "best_res = fitted_models[best_order]\n",
    "print(f\"\\nSelected ARIMA{best_order} by AIC (AIC={best_res.aic:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf2f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 5) Diagnostics on chosen model ----------\n",
    "print(\"\\n=== Model Summary ===\")\n",
    "print(best_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221ca631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plot\n",
    "resid = best_res.resid\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(resid)\n",
    "plt.title(f'Residuals of ARIMA{best_order}')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d4195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual density + mean\n",
    "plt.figure(figsize=(8,4))\n",
    "resid.plot(kind='kde')\n",
    "plt.title('Residual density')\n",
    "plt.show()\n",
    "print(\"Residual mean:\", np.mean(resid), \" Residual std:\", np.std(resid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfded35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF of residuals\n",
    "plt.figure(figsize=(10,4))\n",
    "plot_acf(resid.dropna(), lags=40, zero=False)\n",
    "plt.title('ACF of residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c43e0ea",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Ljung-Box test for no-autocorrelation in residuals\n",
    "lb = acorr_ljungbox(resid.dropna(), lags=[10, 20], return_df=True)\n",
    "print(\"\\nLjung-Box test on residuals:\\n\", lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ab52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 6) Forecasting (out-of-sample) ----------\n",
    "# Forecast horizon = len(test)\n",
    "fc = best_res.get_forecast(steps=len(test))\n",
    "fc_mean = fc.predicted_mean\n",
    "fc_ci = fc.conf_int(alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19527cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into DataFrame for plotting\n",
    "pred_idx = test.index\n",
    "pred_df = pd.DataFrame({'actual': test, 'forecast': fc_mean.values}, index=pred_idx)\n",
    "pred_df[['lower', 'upper']] = fc_ci.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093ac324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs forecast\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(train.index[-(len(test)*3):], train[-len(test)*3:], label='Train (recent part)')\n",
    "plt.plot(test.index, test, label='Actual', marker='o')\n",
    "plt.plot(pred_df.index, pred_df['forecast'], label=f'Forecast ARIMA{best_order}', marker='o')\n",
    "plt.fill_between(pred_df.index, pred_df['lower'], pred_df['upper'], color='gray', alpha=0.2, label='95% CI')\n",
    "plt.title('ARIMA Forecast vs Actual')\n",
    "plt.xlabel('Date'); plt.ylabel('Exchange Rate'); plt.legend(); plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b5760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple numeric metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "rmse = np.sqrt(mean_squared_error(pred_df['actual'], pred_df['forecast']))\n",
    "mae = mean_absolute_error(pred_df['actual'], pred_df['forecast'])\n",
    "mape = np.mean(np.abs((pred_df['actual'] - pred_df['forecast']) / pred_df['actual'])) * 100\n",
    "print(f\"Forecast metrics on test set: RMSE={rmse:.6f}, MAE={mae:.6f}, MAPE={mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf05e25",
   "metadata": {},
   "source": [
    "Save the best model if desired\n",
    "best_res.save(\"best_arima_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
