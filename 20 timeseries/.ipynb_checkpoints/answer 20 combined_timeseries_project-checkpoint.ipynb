{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d5c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ebf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from your directory\n",
    "file_path = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\20 timeseries\\Timeseries\\exchange_rate.csv\"\n",
    "exchange_df = pd.read_csv(file_path, parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a quick preview\n",
    "print(exchange_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ecedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(exchange_df['date'], exchange_df['Ex_rate'], label='USD to AUD Exchange Rate')\n",
    "plt.title('Exchange Rate Over Time (USD → AUD)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Exchange Rate')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cdf04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: ARIMA modelling\n",
    "# Save as arima_part2.py or run in a Jupyter cell.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d32f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2675821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Load data ----------\n",
    "file_path = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\20 timeseries\\Timeseries\\exchange_rate.csv\"\n",
    "df = pd.read_csv(file_path, parse_dates=[0])\n",
    "df.columns = ['date', 'Ex_rate']   # ensure consistent names\n",
    "df = df.sort_values('date').set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e8874",
   "metadata": {},
   "source": [
    "If your data is more granular than monthly, and you want monthly frequency:\n",
    "df = df.asfreq('D')  # only if truly daily; else don't force frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5c3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Quick plot ----------\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(df.index, df['Ex_rate'], label='USD → AUD')\n",
    "plt.title('USD to AUD Exchange Rate')\n",
    "plt.xlabel('Date'); plt.ylabel('Exchange Rate'); plt.grid(True); plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9104d04",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ---------- 1) Stationarity check (ADF test) ----------\n",
    "def adf_report(series, signif=0.05):\n",
    "    res = adfuller(series.dropna(), autolag='AIC')\n",
    "    output = {\n",
    "        'adf_stat': res[0],\n",
    "        'p_value': res[1],\n",
    "        'n_lags': res[2],\n",
    "        'n_obs': res[3],\n",
    "        'crit_vals': res[4]\n",
    "    }\n",
    "    print(\"ADF Statistic: {:.6f}\".format(output['adf_stat']))\n",
    "    print(\"p-value: {:.6f}\".format(output['p_value']))\n",
    "    for k, v in output['crit_vals'].items():\n",
    "        print(\"Critical Value ({}): {:.6f}\".format(k, v))\n",
    "    if output['p_value'] < signif:\n",
    "        print(\"Conclusion: Reject H0 -> series is stationary (at {:.2%} significance).\".format(signif))\n",
    "    else:\n",
    "        print(\"Conclusion: Fail to reject H0 -> series is non-stationary (needs differencing).\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b305689",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"\\n== ADF test on original series ==\")\n",
    "adf_report(df['Ex_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5771275d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# If non-stationary, difference once and test again:\n",
    "df['diff1'] = df['Ex_rate'].diff()\n",
    "print(\"\\n== ADF test on first difference ==\")\n",
    "adf_report(df['diff1'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcba95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 2) ACF and PACF to choose p and q ----------\n",
    "# Plot the ACF and PACF for the (differenced) stationary series\n",
    "series_for_ac = df['diff1'].dropna() if adfuller(df['Ex_rate'].dropna())[1] > 0.05 else df['Ex_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc5901",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plot_acf(series_for_ac, lags=40, zero=False)\n",
    "plt.title('ACF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c3fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plot_pacf(series_for_ac, lags=40, method='ywm')  # use ywm or kubo; ywm is robust\n",
    "plt.title('PACF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcd461f",
   "metadata": {},
   "source": [
    "Based on ACF/PACF you pick p and q:\n",
    "- If PACF cuts off after lag k and ACF tails -> AR(p) with p=k\n",
    "- If ACF cuts off after lag k and PACF tails -> MA(q) with q=k\n",
    "- If both tail -> mixed ARMA\n",
    "We'll pick a few candidate models to try; common approach: try small p/q: 0-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b74850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 3) Train-test split ----------\n",
    "# We'll do a time-series split: last 12 months (or last 10% of samples) for testing\n",
    "n = len(df)\n",
    "test_size = int(0.10 * n)     # use 10% for test\n",
    "train, test = df['Ex_rate'][:-test_size], df['Ex_rate'][-test_size:]\n",
    "print(f\"\\nUsing {len(train)} points for training and {len(test)} for testing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff11377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 4) Fit ARIMA models (try several small combinations) ----------\n",
    "candidate_orders = [(1,1,0), (0,1,1), (1,1,1), (2,1,1), (2,1,0), (0,1,2)]\n",
    "fitted_models = {}\n",
    "for order in candidate_orders:\n",
    "    try:\n",
    "        m = ARIMA(train, order=order)\n",
    "        res = m.fit()\n",
    "        fitted_models[order] = res\n",
    "        print(f\"Fitted ARIMA{order}   AIC: {res.aic:.2f}   BIC: {res.bic:.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ARIMA{order} failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65541903",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Choose best by AIC\n",
    "best_order = min(fitted_models.keys(), key=lambda o: fitted_models[o].aic)\n",
    "best_res = fitted_models[best_order]\n",
    "print(f\"\\nSelected ARIMA{best_order} by AIC (AIC={best_res.aic:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf2f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 5) Diagnostics on chosen model ----------\n",
    "print(\"\\n=== Model Summary ===\")\n",
    "print(best_res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221ca631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plot\n",
    "resid = best_res.resid\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(resid)\n",
    "plt.title(f'Residuals of ARIMA{best_order}')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d4195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual density + mean\n",
    "plt.figure(figsize=(8,4))\n",
    "resid.plot(kind='kde')\n",
    "plt.title('Residual density')\n",
    "plt.show()\n",
    "print(\"Residual mean:\", np.mean(resid), \" Residual std:\", np.std(resid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfded35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF of residuals\n",
    "plt.figure(figsize=(10,4))\n",
    "plot_acf(resid.dropna(), lags=40, zero=False)\n",
    "plt.title('ACF of residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c43e0ea",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Ljung-Box test for no-autocorrelation in residuals\n",
    "lb = acorr_ljungbox(resid.dropna(), lags=[10, 20], return_df=True)\n",
    "print(\"\\nLjung-Box test on residuals:\\n\", lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ab52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 6) Forecasting (out-of-sample) ----------\n",
    "# Forecast horizon = len(test)\n",
    "fc = best_res.get_forecast(steps=len(test))\n",
    "fc_mean = fc.predicted_mean\n",
    "fc_ci = fc.conf_int(alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19527cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into DataFrame for plotting\n",
    "pred_idx = test.index\n",
    "pred_df = pd.DataFrame({'actual': test, 'forecast': fc_mean.values}, index=pred_idx)\n",
    "pred_df[['lower', 'upper']] = fc_ci.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093ac324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs forecast\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(train.index[-(len(test)*3):], train[-len(test)*3:], label='Train (recent part)')\n",
    "plt.plot(test.index, test, label='Actual', marker='o')\n",
    "plt.plot(pred_df.index, pred_df['forecast'], label=f'Forecast ARIMA{best_order}', marker='o')\n",
    "plt.fill_between(pred_df.index, pred_df['lower'], pred_df['upper'], color='gray', alpha=0.2, label='95% CI')\n",
    "plt.title('ARIMA Forecast vs Actual')\n",
    "plt.xlabel('Date'); plt.ylabel('Exchange Rate'); plt.legend(); plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b5760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple numeric metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "rmse = np.sqrt(mean_squared_error(pred_df['actual'], pred_df['forecast']))\n",
    "mae = mean_absolute_error(pred_df['actual'], pred_df['forecast'])\n",
    "mape = np.mean(np.abs((pred_df['actual'] - pred_df['forecast']) / pred_df['actual'])) * 100\n",
    "print(f\"Forecast metrics on test set: RMSE={rmse:.6f}, MAE={mae:.6f}, MAPE={mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf05e25",
   "metadata": {},
   "source": [
    "Save the best model if desired\n",
    "best_res.save(\"best_arima_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c42d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "es_param_optimization.py\n",
    "\n",
    "Parameter optimization for Exponential Smoothing models (SES, Holt, Holt-Winters)\n",
    "- Uses AIC to pick best parameters from a grid\n",
    "- Falls back to statsmodels automatic optimization if grid is disabled or fails\n",
    "\n",
    "Dependencies:\n",
    "  pip install pandas numpy matplotlib statsmodels scikit-learn\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667eaef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f313b291",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8cc848",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def infer_seasonal_period(ts, max_period=24):\n",
    "    \"\"\"\n",
    "    Try to infer a seasonal period by autocorrelation peak.\n",
    "    Simple heuristic: look for the lag (<= max_period) with the highest AC at lag>0.\n",
    "    Returns an int seasonality or None.\n",
    "    \"\"\"\n",
    "    from statsmodels.tsa.stattools import acf\n",
    "    acfs = acf(ts.dropna(), nlags=min(len(ts)//2, max_period), fft=True)\n",
    "    # ignore lag 0\n",
    "    if len(acfs) < 2:\n",
    "        return None\n",
    "    lag = int(np.argmax(acfs[1:]) + 1)\n",
    "    if acfs[lag] > 0.3:  # threshold heuristic; lower for noisy data\n",
    "        return lag\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6dab6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def grid_search_es(ts,\n",
    "                   model_type='auto',  # 'ses', 'holt', 'hw' or 'auto'\n",
    "                   seasonal_periods=None,\n",
    "                   alphas=None, betas=None, gammas=None,\n",
    "                   use_grid=True,\n",
    "                   max_combinations=200):\n",
    "    \"\"\"\n",
    "    Grid-search AIC for ExponentialSmoothing models.\n",
    "    Returns (best_fit, best_params, results_df)\n",
    "    \"\"\"\n",
    "    ts = ts.dropna()\n",
    "    n = len(ts)\n",
    "    results = []\n",
    "\n",
    "    # Decide which model to run\n",
    "    if model_type == 'auto':\n",
    "        # try to detect seasonality\n",
    "        if seasonal_periods is None:\n",
    "            seasonal_periods = infer_seasonal_period(ts)\n",
    "        if seasonal_periods and seasonal_periods >= 2:\n",
    "            chosen = 'hw'  # Holt-Winters\n",
    "        else:\n",
    "            # check for linear trend via simple difference of means slope\n",
    "            slope = (ts.iloc[-1] - ts.iloc[0]) / max(n-1, 1)\n",
    "            # if slope magnitude is significant relative to series std -> trend\n",
    "            if abs(slope) > 0.1 * np.std(ts):\n",
    "                chosen = 'holt'\n",
    "            else:\n",
    "                chosen = 'ses'\n",
    "    else:\n",
    "        chosen = model_type\n",
    "\n",
    "    print(f\"Chosen model: {chosen}, seasonal_periods={seasonal_periods}\")\n",
    "\n",
    "    # Default parameter grids\n",
    "    if alphas is None:\n",
    "        alphas = np.linspace(0.01, 0.99, 9)\n",
    "    if betas is None:\n",
    "        betas = np.linspace(0.01, 0.99, 7)\n",
    "    if gammas is None:\n",
    "        gammas = np.linspace(0.01, 0.99, 7)\n",
    "\n",
    "    # Build candidate list\n",
    "    candidates = []\n",
    "\n",
    "    if chosen == 'ses':\n",
    "        for a in alphas:\n",
    "            candidates.append({'smoothing_level': float(a)})\n",
    "    elif chosen == 'holt':\n",
    "        for a, b in product(alphas, betas):\n",
    "            candidates.append({'smoothing_level': float(a), 'smoothing_slope': float(b)})\n",
    "    else:  # hw\n",
    "        if seasonal_periods is None:\n",
    "            raise ValueError(\"seasonal_periods must be provided or inferable for Holt-Winters\")\n",
    "        for a, b, g in product(alphas, betas, gammas):\n",
    "            candidates.append({'smoothing_level': float(a),\n",
    "                               'smoothing_slope': float(b),\n",
    "                               'smoothing_seasonal': float(g)})\n",
    "\n",
    "    # if too many candidates, reduce by sampling\n",
    "    if use_grid and len(candidates) > max_combinations:\n",
    "        np.random.seed(0)\n",
    "        candidates = list(np.random.choice(candidates, size=max_combinations, replace=False))\n",
    "\n",
    "    best_aic = np.inf\n",
    "    best_fit = None\n",
    "    best_params = None\n",
    "\n",
    "    if not use_grid:\n",
    "        # Let statsmodels optimize\n",
    "        print(\"Grid disabled — using statsmodels optimized=True\")\n",
    "        try:\n",
    "            if chosen == 'ses':\n",
    "                model = ExponentialSmoothing(ts, trend=None, seasonal=None)\n",
    "            elif chosen == 'holt':\n",
    "                model = ExponentialSmoothing(ts, trend='add', seasonal=None)\n",
    "            else:\n",
    "                model = ExponentialSmoothing(ts, trend='add', seasonal='add', seasonal_periods=seasonal_periods)\n",
    "            fit = model.fit(optimized=True)\n",
    "            return fit, fit.params, None\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"Optimized fit failed: \" + str(e))\n",
    "\n",
    "    # run grid\n",
    "    for i, params in enumerate(candidates, 1):\n",
    "        try:\n",
    "            if chosen == 'ses':\n",
    "                model = ExponentialSmoothing(ts, trend=None, seasonal=None)\n",
    "                fit = model.fit(smoothing_level=params['smoothing_level'], optimized=False)\n",
    "            elif chosen == 'holt':\n",
    "                model = ExponentialSmoothing(ts, trend='add', seasonal=None)\n",
    "                fit = model.fit(smoothing_level=params['smoothing_level'],\n",
    "                                smoothing_slope=params['smoothing_slope'],\n",
    "                                optimized=False)\n",
    "            else:\n",
    "                model = ExponentialSmoothing(ts, trend='add', seasonal='add', seasonal_periods=seasonal_periods)\n",
    "                fit = model.fit(smoothing_level=params['smoothing_level'],\n",
    "                                smoothing_slope=params['smoothing_slope'],\n",
    "                                smoothing_seasonal=params['smoothing_seasonal'],\n",
    "                                optimized=False)\n",
    "            aic = getattr(fit, 'aic', np.inf)\n",
    "            results.append({'params': params, 'aic': aic, 'llf': getattr(fit, 'llf', None)})\n",
    "            if aic < best_aic:\n",
    "                best_aic = aic\n",
    "                best_fit = fit\n",
    "                best_params = params\n",
    "        except Exception as e:\n",
    "            # skip invalid combos (can happen when model can't converge)\n",
    "            # print(f\"skip params {params}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if best_fit is None:\n",
    "        raise RuntimeError(\"Grid search failed to fit any model; try optimized=True or different grid ranges\")\n",
    "\n",
    "    # build results DataFrame for inspection\n",
    "    results_df = pd.DataFrame([{'aic': r['aic'], **r['params']} for r in results]).sort_values('aic').reset_index(drop=True)\n",
    "\n",
    "    print(\"Best AIC:\", best_aic)\n",
    "    print(\"Best params:\", best_params)\n",
    "    return best_fit, best_params, results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Example usage with sample series\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: synthetic monthly series with trend + seasonality\n",
    "    rng = pd.date_range('2015-01-01', periods=120, freq='M')\n",
    "    np.random.seed(42)\n",
    "    seasonal = 10 * np.sin(2 * np.pi * (np.arange(len(rng)) % 12) / 12)\n",
    "    trend = 0.5 * np.arange(len(rng))\n",
    "    noise = np.random.normal(scale=3, size=len(rng))\n",
    "    data = 50 + trend + seasonal + noise\n",
    "    ts = pd.Series(data, index=rng)\n",
    "\n",
    "    # Run grid search (auto model detection)\n",
    "    fit, best_params, results_df = grid_search_es(ts, model_type='auto', seasonal_periods=None, use_grid=True)\n",
    "\n",
    "    # Forecast example\n",
    "    steps = 12\n",
    "    forecast = fit.forecast(steps)\n",
    "\n",
    "    # Print short diagnostics\n",
    "    print(\"\\nFitted params from statsmodels fit object:\")\n",
    "    print(fit.params)\n",
    "    print(\"\\nTop 5 grid results (first rows):\")\n",
    "    if results_df is not None:\n",
    "        print(results_df.head())\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(ts, label='Actual')\n",
    "    plt.plot(fit.fittedvalues, label='Fitted', linestyle='--')\n",
    "    plt.plot(forecast, label='Forecast', linestyle='-.')\n",
    "    plt.title(\"Exponential Smoothing - Fitted vs Forecast\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Quick error measure on last 'steps' if you want a rough holdout (not strict CV)\n",
    "    try:\n",
    "        last_actual = ts[-steps:]\n",
    "        # align forecast length\n",
    "        fa = forecast[:len(last_actual)]\n",
    "        print(\"MAE (last periods):\", mean_absolute_error(last_actual, fa))\n",
    "        print(\"RMSE (last periods):\", mean_squared_error(last_actual, fa, squared=False))\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a1b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 4: Model Evaluation and Comparison\n",
    "---------------------------------------\n",
    "Compares ARIMA and Exponential Smoothing forecasts using MAE, RMSE, and MAPE.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e8334",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --- Example setup: replace with your actual fitted models and series ---\n",
    "# Suppose 'test' is your test set, 'forecast_hw' and 'forecast_arima' are their forecasts.\n",
    "# For demonstration, we’ll fake some data:\n",
    "np.random.seed(42)\n",
    "test = pd.Series(np.random.uniform(80, 85, 12), name='Actual')  # actual exchange rate\n",
    "forecast_hw = test + np.random.normal(0, 0.3, 12)               # Holt-Winters forecast\n",
    "forecast_arima = test + np.random.normal(0, 0.5, 12)            # ARIMA forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4ea652",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --- Define evaluation functions ---\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2f5468",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    return pd.Series({'MAE': mae, 'RMSE': rmse, 'MAPE': mape}, name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae847cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute metrics for both models ---\n",
    "results_hw = evaluate_model(test, forecast_hw, 'Holt-Winters')\n",
    "results_arima = evaluate_model(test, forecast_arima, 'ARIMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb2cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat([results_hw, results_arima], axis=1).T\n",
    "print(\"\\n🔹 Forecast Error Metrics Comparison:\\n\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edfea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visual comparison ---\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(test.values, label='Actual', color='black', marker='o')\n",
    "plt.plot(forecast_hw.values, label='Holt-Winters Forecast', linestyle='--', marker='x')\n",
    "plt.plot(forecast_arima.values, label='ARIMA Forecast', linestyle='-.', marker='s')\n",
    "plt.title(\"Exchange Rate Forecast Comparison\")\n",
    "plt.xlabel(\"Time Steps (Test Periods)\")\n",
    "plt.ylabel(\"Exchange Rate\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae54fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Identify best model ---\n",
    "best_model = results_df['RMSE'].idxmin()\n",
    "print(f\"\\n🏆 Best model based on RMSE: {best_model}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97d0454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optional: difference plot for error visualization ---\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(['Holt-Winters', 'ARIMA'], results_df['RMSE'], color=['#66c2a5', '#fc8d62'])\n",
    "plt.title(\"Model RMSE Comparison\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
