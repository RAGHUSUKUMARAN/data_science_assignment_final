{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a53738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using train: D:\\DATA SCIENCE\\ASSIGNMENTS\\7 logistic regression\\files\\Logistic Regression\\Titanic_train.csv\n",
      "Using test : D:\\DATA SCIENCE\\ASSIGNMENTS\\7 logistic regression\\files\\Logistic Regression\\Titanic_test.csv\n",
      "\n",
      "Train shape: (891, 12)\n",
      " PassengerId  Survived  Pclass                                                Name    Sex  Age  SibSp  Parch           Ticket    Fare Cabin Embarked\n",
      "           1         0       3                             Braund, Mr. Owen Harris   male 22.0      1      0        A/5 21171  7.2500   NaN        S\n",
      "           2         1       1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38.0      1      0         PC 17599 71.2833   C85        C\n",
      "           3         1       3                              Heikkinen, Miss. Laina female 26.0      0      0 STON/O2. 3101282  7.9250   NaN        S\n",
      "\n",
      "Missing values (train):\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "Numeric features: ['Age', 'SibSp', 'Parch', 'Fare']\n",
      "Categorical features: ['Pclass', 'Sex', 'Embarked', 'Title', 'HasCabin']\n",
      "Saved test_predictions.csv\n",
      "\n",
      "5-fold CV ROC-AUC: [0.90217391 0.86804813 0.84859626 0.85614973 0.89436245]\n",
      "Mean CV AUC: 0.8738660964984317\n",
      "\n",
      "Top coefficients:\n",
      "         feature      coef  abs_coef\n",
      "    Title_Master  1.868946  1.868946\n",
      "      Sex_female  1.308113  1.308113\n",
      "        Title_Mr -1.123596  1.123596\n",
      "      HasCabin_1  0.816541  0.816541\n",
      "       Title_Mrs  0.784405  0.784405\n",
      "          Pclass -0.750654  0.750654\n",
      "      Title_Rare -0.667185  0.667185\n",
      "           SibSp -0.545661  0.545661\n",
      "      Embarked_C  0.443260  0.443260\n",
      "        Sex_male -0.397860  0.397860\n",
      "             Age -0.354077  0.354077\n",
      "      Embarked_Q  0.297710  0.297710\n",
      "           Parch -0.267872  0.267872\n",
      "            Fare  0.148422  0.148422\n",
      "Embarked_Missing  0.116045  0.116045\n",
      "\n",
      "Saved model to titanic_logreg_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# Titanic â€” Logistic Regression (Notebook)\n",
    "# \n",
    "# Author: Maddy\n",
    "# Deliverable: Single .ipynb file covering EDA, preprocessing, model training, evaluation, interpretation, and saving artifacts.\n",
    "\n",
    "# %%\n",
    "# 1. Imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, roc_curve, confusion_matrix, classification_report)\n",
    "import joblib\n",
    "\n",
    "# %%\n",
    "# 2. File paths (adjust if needed)\n",
    "POSSIBLE_TRAIN = [\n",
    "    \"/mnt/data/Titanic_train.csv\",\n",
    "    \"Titanic_train.csv\",\n",
    "    r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\7 logistic regression\\files\\Logistic Regression\\Titanic_train.csv\",\n",
    "]\n",
    "POSSIBLE_TEST = [\n",
    "    \"/mnt/data/Titanic_test.csv\",\n",
    "    \"Titanic_test.csv\",\n",
    "    r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\7 logistic regression\\files\\Logistic Regression\\Titanic_test.csv\",\n",
    "]\n",
    "\n",
    "TRAIN_PATH = next((p for p in POSSIBLE_TRAIN if Path(p).exists()), None)\n",
    "TEST_PATH = next((p for p in POSSIBLE_TEST if Path(p).exists()), None)\n",
    "\n",
    "if TRAIN_PATH is None:\n",
    "    raise FileNotFoundError(\"Couldn't find Titanic_train.csv. Place it in the working folder or update TRAIN_PATH list.\")\n",
    "\n",
    "print('Using train:', TRAIN_PATH)\n",
    "print('Using test :', TEST_PATH)\n",
    "\n",
    "# Create plots folder\n",
    "PLOT_DIR = Path(\"plots\")\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# %%\n",
    "# 3. Load data & quick EDA\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH) if TEST_PATH else None\n",
    "\n",
    "print('\\nTrain shape:', train.shape)\n",
    "print(train.head(3).to_string(index=False))\n",
    "print('\\nMissing values (train):')\n",
    "print(train.isnull().sum())\n",
    "\n",
    "# Quick distributions\n",
    "for col in ['Age','Fare']:\n",
    "    if col in train.columns:\n",
    "        plt.figure(figsize=(6,3))\n",
    "        sns.histplot(train[col].dropna(), kde=True)\n",
    "        plt.title(col)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(PLOT_DIR/f\"hist_{col}.png\")\n",
    "        plt.close()\n",
    "\n",
    "# %%\n",
    "# 4. Feature engineering & preprocessing helpers\n",
    "\n",
    "def extract_title(name):\n",
    "    if pd.isna(name):\n",
    "        return 'Unknown'\n",
    "    parts = name.split(',')\n",
    "    if len(parts) > 1:\n",
    "        token = parts[1].split('.')[0].strip()\n",
    "        return token\n",
    "    return 'Unknown'\n",
    "\n",
    "\n",
    "def prepare_features(df):\n",
    "    df = df.copy()\n",
    "    if 'Name' in df.columns:\n",
    "        df['Title'] = df['Name'].apply(extract_title)\n",
    "        df['Title'] = df['Title'].replace(['Mlle','Ms','Mme'], ['Miss','Miss','Mrs'])\n",
    "        rare = ['Lady','the Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona']\n",
    "        df['Title'] = df['Title'].replace(rare, 'Rare')\n",
    "    if 'Cabin' in df.columns:\n",
    "        df['HasCabin'] = df['Cabin'].notnull().astype(int)\n",
    "    if 'Embarked' in df.columns:\n",
    "        df['Embarked'] = df['Embarked'].fillna('Missing')\n",
    "    return df\n",
    "\n",
    "train = prepare_features(train)\n",
    "if test is not None:\n",
    "    test = prepare_features(test)\n",
    "\n",
    "# %%\n",
    "# 5. Define X, y, feature groups\n",
    "TARGET = 'Survived'\n",
    "drop_cols = ['PassengerId','Ticket','Cabin','Name']\n",
    "\n",
    "if TARGET in train.columns:\n",
    "    X = train.drop(columns=[TARGET] + [c for c in drop_cols if c in train.columns])\n",
    "    y = train[TARGET]\n",
    "else:\n",
    "    X = train.drop(columns=[c for c in drop_cols if c in train.columns])\n",
    "    y = None\n",
    "\n",
    "X_test_file = None\n",
    "y_test_file = None\n",
    "if test is not None:\n",
    "    if 'Survived' in test.columns:\n",
    "        X_test_file = test.drop(columns=[TARGET] + [c for c in drop_cols if c in test.columns])\n",
    "        y_test_file = test[TARGET]\n",
    "    else:\n",
    "        X_test_file = test.drop(columns=[c for c in drop_cols if c in test.columns])\n",
    "\n",
    "numeric_features = [c for c in ['Age','SibSp','Parch','Fare'] if c in X.columns]\n",
    "categorical_features = [c for c in ['Pclass','Sex','Embarked','Title','HasCabin'] if c in X.columns]\n",
    "\n",
    "print('\\nNumeric features:', numeric_features)\n",
    "print('Categorical features:', categorical_features)\n",
    "\n",
    "# %%\n",
    "# 6. Build preprocessing + pipeline\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "\n",
    "ohe_features = [c for c in categorical_features if c != 'Pclass']\n",
    "cat_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                  ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "transformers = []\n",
    "if numeric_features:\n",
    "    transformers.append(('num', numeric_transformer, numeric_features))\n",
    "if ohe_features:\n",
    "    transformers.append(('ohe', cat_transformer, ohe_features))\n",
    "if 'Pclass' in categorical_features:\n",
    "    transformers.append(('pclass_passthrough', 'passthrough', ['Pclass']))\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=transformers)\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('clf', LogisticRegression(solver='liblinear', max_iter=1000, random_state=42))])\n",
    "\n",
    "# %%\n",
    "# 7. Train / validate\n",
    "if X_test_file is None:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    print('\\nTrain/Valid shapes:', X_train.shape, X_valid.shape)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    y_proba = clf.predict_proba(X_valid)[:,1]\n",
    "    eval_name = 'Validation'\n",
    "    eval_y = y_valid\n",
    "else:\n",
    "    clf.fit(X, y)\n",
    "    if y_test_file is not None:\n",
    "        y_pred = clf.predict(X_test_file)\n",
    "        y_proba = clf.predict_proba(X_test_file)[:,1]\n",
    "        eval_name = 'Provided test file'\n",
    "        eval_y = y_test_file\n",
    "    else:\n",
    "        # unlabeled test -> produce predictions only\n",
    "        preds = clf.predict(X_test_file)\n",
    "        out = X_test_file.copy()\n",
    "        out['Survived'] = preds\n",
    "        out.to_csv('test_predictions.csv', index=False)\n",
    "        print('Saved test_predictions.csv')\n",
    "        eval_name = None\n",
    "\n",
    "# %%\n",
    "# 8. Evaluation utilities\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate(name, y_true, y_pred, y_proba):\n",
    "    print(f\"\\n=== Evaluation on {name} ===\")\n",
    "    print('Accuracy:', accuracy_score(y_true,y_pred))\n",
    "    print('Precision:', precision_score(y_true,y_pred))\n",
    "    print('Recall:', recall_score(y_true,y_pred))\n",
    "    print('F1:', f1_score(y_true,y_pred))\n",
    "    print('ROC-AUC:', roc_auc_score(y_true,y_proba))\n",
    "    print('\\nClassification report:')\n",
    "    print(classification_report(y_true,y_pred))\n",
    "\n",
    "    # confusion matrix and ROC\n",
    "    cm = confusion_matrix(y_true,y_pred)\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d')\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.savefig(PLOT_DIR/f'confusion_{name}.png')\n",
    "    plt.close()\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.plot(fpr,tpr,label=f'AUC={roc_auc_score(y_true,y_proba):.3f}')\n",
    "    plt.plot([0,1],[0,1],'--')\n",
    "    plt.xlabel('FPR'); plt.ylabel('TPR'); plt.legend()\n",
    "    plt.savefig(PLOT_DIR/f'roc_{name}.png')\n",
    "    plt.close()\n",
    "\n",
    "if eval_name:\n",
    "    metrics = evaluate(eval_name, eval_y, y_pred, y_proba)\n",
    "\n",
    "# %%\n",
    "# 9. Cross-validation and feature importance\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(clf, X, y, scoring='roc_auc', cv=cv)\n",
    "print('\\n5-fold CV ROC-AUC:', cv_scores)\n",
    "print('Mean CV AUC:', cv_scores.mean())\n",
    "\n",
    "# feature names and coefficients\n",
    "\n",
    "def get_feature_names(column_transformer):\n",
    "    names = []\n",
    "    for name, trans, cols in column_transformer.transformers_:\n",
    "        if trans == 'passthrough':\n",
    "            if isinstance(cols, (list,tuple)):\n",
    "                names.extend(cols)\n",
    "            else:\n",
    "                names.append(cols)\n",
    "            continue\n",
    "        if hasattr(trans, 'named_steps'):\n",
    "            last = list(trans.named_steps.items())[-1][1]\n",
    "        else:\n",
    "            last = trans\n",
    "        if hasattr(last, 'get_feature_names_out'):\n",
    "            try:\n",
    "                out = last.get_feature_names_out(cols if isinstance(cols,(list,tuple)) else [cols])\n",
    "                names.extend(out.tolist())\n",
    "            except Exception:\n",
    "                if isinstance(cols,(list,tuple)):\n",
    "                    names.extend(cols)\n",
    "                else:\n",
    "                    names.append(cols)\n",
    "        else:\n",
    "            if isinstance(cols,(list,tuple)):\n",
    "                names.extend(cols)\n",
    "            else:\n",
    "                names.append(cols)\n",
    "    return names\n",
    "\n",
    "feat_names = get_feature_names(clf.named_steps['preprocessor'])\n",
    "coefs = clf.named_steps['clf'].coef_[0]\n",
    "coef_df = pd.DataFrame({'feature': feat_names[:len(coefs)], 'coef': coefs})\n",
    "coef_df['abs_coef'] = coef_df['coef'].abs()\n",
    "coef_df = coef_df.sort_values('abs_coef', ascending=False)\n",
    "print('\\nTop coefficients:')\n",
    "print(coef_df.head(15).to_string(index=False))\n",
    "\n",
    "# %%\n",
    "# 10. Save model and artifacts\n",
    "joblib.dump(clf, 'titanic_logreg_pipeline.joblib')\n",
    "print('\\nSaved model to titanic_logreg_pipeline.joblib')\n",
    "\n",
    "# Save coef table and metrics\n",
    "coef_df.to_csv('logreg_coefficients.csv', index=False)\n",
    "if eval_name:\n",
    "    pd.Series({'cv_auc_mean': cv_scores.mean()}).to_csv('logreg_metrics_summary.csv')\n",
    "\n",
    "# %% [markdown]\n",
    "# End of notebook\n",
    "# - Files produced: `titanic_logreg_pipeline.joblib`, `logreg_coefficients.csv`, `logreg_metrics_summary.csv` (if evaluation ran), and images in `plots/`.\n",
    "# - To run app: place `model.joblib` (or `titanic_logreg_pipeline.joblib`) and `app.py` together and run `streamlit run app.py`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
