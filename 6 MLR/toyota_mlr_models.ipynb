{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26bd860",
   "metadata": {},
   "source": [
    "toyota_mlr_models.py\n",
    "Build 3+ regression models (OLS, OLS with backward selection, Ridge) and evaluate them.\n",
    "Expects either saved splits in D:\\DATA SCIENCE\\ASSIGNMENTS\\6 MLR\\MLR\\splits\n",
    "or will load the cleaned CSV and create a fresh train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e464d2a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstatsmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msm\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c4600a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ---------- CONFIG ----------\n",
    "SPLITS_DIR = Path(r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\6 MLR\\MLR\\splits\")\n",
    "CLEANED_CSV = Path(r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\6 MLR\\MLR\\ToyotaCorolla_MLR_cleaned.csv\")\n",
    "ORIG_CSV = Path(r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\6 MLR\\MLR\\ToyotaCorolla - MLR.csv\")\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ae068e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ---------- Helpers ----------\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01986f80",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def print_metrics(name, y_true, y_pred):\n",
    "    print(f\"\\n{name} performance:\")\n",
    "    print(\" MAE:  \", round(mean_absolute_error(y_true, y_pred), 3))\n",
    "    print(\" RMSE: \", round(rmse(y_true, y_pred), 3))\n",
    "    print(\" R2:   \", round(r2_score(y_true, y_pred), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe07136",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def fit_ols_and_report(X_train, y_train, X_test, y_test, model_name=\"OLS\"):\n",
    "    Xtr_sm = add_constant(X_train, has_constant='add')\n",
    "    ols = sm.OLS(y_train.astype(float), Xtr_sm.astype(float)).fit()\n",
    "    print(f\"\\n=== {model_name} summary ===\")\n",
    "    print(ols.summary())\n",
    "    preds = ols.predict(add_constant(X_test, has_constant='add').astype(float))\n",
    "    print_metrics(model_name, y_test, preds)\n",
    "    coef_table = pd.DataFrame({\n",
    "        'feature': ['const'] + list(X_train.columns),\n",
    "        'coef': np.round(ols.params.values, 4)\n",
    "    })\n",
    "    print(\"\\nCoefficients:\")\n",
    "    print(coef_table.to_string(index=False))\n",
    "    return ols, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949cae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Load data / splits ----------\n",
    "if SPLITS_DIR.exists() and (SPLITS_DIR / \"X_train.csv\").exists():\n",
    "    print(\"Loading saved splits from:\", SPLITS_DIR)\n",
    "    X_train = pd.read_csv(SPLITS_DIR / \"X_train.csv\")\n",
    "    X_test  = pd.read_csv(SPLITS_DIR / \"X_test.csv\")\n",
    "    y_train = pd.read_csv(SPLITS_DIR / \"y_train.csv\").squeeze()\n",
    "    y_test  = pd.read_csv(SPLITS_DIR / \"y_test.csv\").squeeze()\n",
    "else:\n",
    "    # load cleaned if exists else original\n",
    "    if CLEANED_CSV.exists():\n",
    "        df = pd.read_csv(CLEANED_CSV)\n",
    "    else:\n",
    "        df = pd.read_csv(ORIG_CSV)\n",
    "        # minimal cleaning: ensure numeric columns and dummies for Fuel_Type if present\n",
    "        for c in df.columns:\n",
    "            if c != \"Fuel_Type\":\n",
    "                df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "        if \"Fuel_Type\" in df.columns:\n",
    "            df[\"Fuel_Type\"] = df[\"Fuel_Type\"].astype(str).str.strip()\n",
    "            df = pd.get_dummies(df, columns=[\"Fuel_Type\"], drop_first=True)\n",
    "        df = df.dropna(subset=[\"Price\"])\n",
    "    # define features: use all numeric except Price (the cleaned file includes prepared columns)\n",
    "    target = \"Price\"\n",
    "    feature_cols = [c for c in df.columns if c != target]\n",
    "    X = df[feature_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    y = pd.to_numeric(df[target], errors='coerce')\n",
    "    mask = X.dropna().index.intersection(y.dropna().index)\n",
    "    X = X.loc[mask]\n",
    "    y = y.loc[mask]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "    print(f\"Created fresh split: Train {X_train.shape}, Test {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0304c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure indices are aligned and types numeric\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "X_test  = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "y_train = pd.to_numeric(y_train, errors='coerce')\n",
    "y_test  = pd.to_numeric(y_test, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ad0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaNs just in case\n",
    "train_idx = X_train.dropna().index.intersection(y_train.dropna().index)\n",
    "test_idx  = X_test.dropna().index.intersection(y_test.dropna().index)\n",
    "X_train = X_train.loc[train_idx].copy(); y_train = y_train.loc[train_idx].copy()\n",
    "X_test  = X_test.loc[test_idx].copy();  y_test  = y_test.loc[test_idx].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d796dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFinal feature set used:\", list(X_train.columns))\n",
    "print(\"Train size:\", X_train.shape, \" Test size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82bc5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- MODEL 1: Baseline OLS (all features) ----------\n",
    "ols_all, preds_all = fit_ols_and_report(X_train, y_train, X_test, y_test, model_name=\"Model A - OLS (all features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f5b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- MODEL 2: Backward elimination (p-value) OLS ----------\n",
    "# iterative removal of highest p-value > threshold (0.05)\n",
    "print(\"\\n--- Building Model B via backward elimination (p-value) ---\")\n",
    "Xb = X_train.copy()\n",
    "yb = y_train.copy()\n",
    "p_thresh = 0.05\n",
    "while True:\n",
    "    Xb_sm = add_constant(Xb, has_constant='add')\n",
    "    model = sm.OLS(yb.astype(float), Xb_sm.astype(float)).fit()\n",
    "    pvals = model.pvalues.drop('const', errors='ignore')\n",
    "    if pvals.empty:\n",
    "        break\n",
    "    max_p = pvals.max()\n",
    "    if max_p > p_thresh:\n",
    "        drop_col = pvals.idxmax()\n",
    "        print(f\" Dropping {drop_col} with p-value {max_p:.4f}\")\n",
    "        Xb = Xb.drop(columns=[drop_col])\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c26ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_sel, preds_sel = fit_ols_and_report(Xb, yb, X_test[Xb.columns], y_test, model_name=\"Model B - OLS (backward selection)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- MODEL 3: Ridge regression (regularized) ----------\n",
    "print(\"\\n--- Building Model C: RidgeCV (with scaling) ---\")\n",
    "scaler = StandardScaler()\n",
    "Xtr_s = scaler.fit_transform(X_train)\n",
    "Xte_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17103320",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-3, 3, 50)\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=5).fit(Xtr_s, y_train)\n",
    "print(\"Ridge chosen alpha:\", ridge_cv.alpha_)\n",
    "preds_ridge = ridge_cv.predict(Xte_s)\n",
    "print_metrics = print_metrics  # alias\n",
    "print_metrics(\"Model C - RidgeCV\", y_test, preds_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4883cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients for ridge (map back to feature names)\n",
    "ridge_coefs = pd.DataFrame({\n",
    "    'feature': list(X_train.columns),\n",
    "    'ridge_coef': np.round(ridge_cv.coef_, 4)\n",
    "})\n",
    "print(\"\\nRidge coefficients:\")\n",
    "print(ridge_coefs.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c142cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Compare models on test set ----------\n",
    "print(\"\\n=== Summary comparison on test set ===\")\n",
    "print_metrics(\"Model A - OLS (all features)\", y_test, preds_all)\n",
    "print_metrics(\"Model B - OLS (selected)\", y_test, preds_sel)\n",
    "print_metrics(\"Model C - RidgeCV\", y_test, preds_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model coefficient tables for reporting\n",
    "coef_A = pd.DataFrame({'feature': ['const'] + list(X_train.columns), 'coef_A': np.round(ols_all.params.values,4)})\n",
    "coef_B = pd.DataFrame({'feature': ['const'] + list(Xb.columns), 'coef_B': np.round(ols_sel.params.values,4)})\n",
    "coef_R = ridge_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc40c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_out = Path(r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\6 MLR\\MLR\").joinpath(\"model_coefficients_summary.csv\")\n",
    "coef_df = coef_A.merge(coef_B, on='feature', how='outer').merge(coef_R, on='feature', how='outer')\n",
    "coef_df.to_csv(coef_out, index=False)\n",
    "print(\"\\nSaved coefficient summary to:\", coef_out)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
