{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune_decision_tree.py\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d309ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0ad070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- CONFIG ----------------\n",
    "BASE_PATH = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\13 decision tree\\Decision Tree\"\n",
    "RAW_XLSX = os.path.join(BASE_PATH, \"heart_disease.xlsx\")\n",
    "PROCESSED_CSV = os.path.join(BASE_PATH, \"heart_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd006b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_BEST_MODEL = os.path.join(BASE_PATH, \"decision_tree_best.pkl\")\n",
    "OUT_CV_RESULTS = os.path.join(BASE_PATH, \"gridsearch_cv_results.csv\")\n",
    "OUT_BEST_PARAMS = os.path.join(BASE_PATH, \"best_params.txt\")\n",
    "OUT_REPORT = os.path.join(BASE_PATH, \"decision_tree_tuned_report.txt\")\n",
    "OUT_FI_PNG = os.path.join(BASE_PATH, \"feature_importances.png\")\n",
    "OUT_TREE_PNG = os.path.join(BASE_PATH, \"decision_tree_best.png\")\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "# ----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2978998",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def ensure_processed():\n",
    "    \"\"\"Create processed CSV if missing (light FE similar to earlier steps).\"\"\"\n",
    "    if os.path.exists(PROCESSED_CSV):\n",
    "        print(\"Found processed CSV:\", PROCESSED_CSV)\n",
    "        return pd.read_csv(PROCESSED_CSV)\n",
    "    print(\"Processed CSV not found. Generating from raw Excel...\")\n",
    "    df = pd.read_excel(RAW_XLSX, sheet_name=\"Heart_disease\")\n",
    "    df['oldpeak'] = df['oldpeak'].fillna(df['oldpeak'].median())\n",
    "    for col in ['trestbps', 'chol']:\n",
    "        df[col] = df[col].replace(0, np.nan).fillna(df[col].median())\n",
    "    df['sex'] = df['sex'].map({'Male':1, 'Female':0})\n",
    "    for col in ['fbs','exang']:\n",
    "        if df[col].dtype == bool:\n",
    "            df[col] = df[col].astype(int)\n",
    "        else:\n",
    "            df[col] = df[col].map({'True':1,'TURE':1,'False':0,'FALSE':0}).fillna(0).astype(int)\n",
    "    df['target'] = df['num'].apply(lambda x: 1 if x>0 else 0)\n",
    "    cat_cols = [c for c in ['cp','restecg','slope','thal'] if c in df.columns]\n",
    "    df_processed = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "    if 'num' in df_processed.columns:\n",
    "        df_processed = df_processed.drop(columns=['num'])\n",
    "    df_processed.to_csv(PROCESSED_CSV, index=False)\n",
    "    print(\"Saved processed CSV to:\", PROCESSED_CSV)\n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e729aaef",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = ensure_processed()\n",
    "    if 'target' not in df.columns:\n",
    "        raise RuntimeError(\"Processed data missing 'target' column.\")\n",
    "    X = df.drop(columns=['target'])\n",
    "    y = df['target']\n",
    "\n",
    "    # train/test split (stratified)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
    "    )\n",
    "    print(\"Train/test shapes:\", X_train.shape, X_test.shape)\n",
    "\n",
    "    # parameter grid (sane but not huge)\n",
    "    param_grid = {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 3, 5, 7, 9, 12],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'min_samples_leaf': [1, 2, 4, 8],\n",
    "        'max_features': [None, 'sqrt', 'log2']\n",
    "    }\n",
    "\n",
    "    # Stratified CV\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    base_clf = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=base_clf,\n",
    "        param_grid=param_grid,\n",
    "        scoring='roc_auc',\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    print(\"Starting GridSearchCV... (this may take a few minutes)\")\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"GridSearchCV done.\")\n",
    "\n",
    "    # Save CV results\n",
    "    cv_results = pd.DataFrame(grid.cv_results_)\n",
    "    cv_results.to_csv(OUT_CV_RESULTS, index=False)\n",
    "    print(\"Saved CV results to:\", OUT_CV_RESULTS)\n",
    "\n",
    "    # Best estimator & params\n",
    "    best = grid.best_estimator_\n",
    "    best_params = grid.best_params_\n",
    "    best_score = grid.best_score_\n",
    "    with open(OUT_BEST_PARAMS, \"w\") as f:\n",
    "        f.write(f\"Best ROC-AUC (CV): {best_score:.5f}\\n\")\n",
    "        f.write(\"Best params:\\n\")\n",
    "        for k,v in best_params.items():\n",
    "            f.write(f\"{k}: {v}\\n\")\n",
    "    print(\"Saved best params to:\", OUT_BEST_PARAMS)\n",
    "\n",
    "    # Save best model\n",
    "    joblib.dump(best, OUT_BEST_MODEL)\n",
    "    print(\"Saved best model to:\", OUT_BEST_MODEL)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_pred = best.predict(X_test)\n",
    "    y_proba = best.predict_proba(X_test)[:,1] if hasattr(best, \"predict_proba\") else None\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else float(\"nan\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Save evaluation report\n",
    "    with open(OUT_REPORT, \"w\") as f:\n",
    "        f.write(\"Decision Tree — Tuned Model Evaluation\\n\\n\")\n",
    "        f.write(f\"Test shape: {X_test.shape}\\n\\n\")\n",
    "        f.write(f\"Accuracy: {acc:.4f}\\nPrecision: {prec:.4f}\\nRecall: {rec:.4f}\\nF1-score: {f1:.4f}\\nROC-AUC: {roc_auc:.4f}\\n\\n\")\n",
    "        f.write(\"Confusion Matrix:\\n\")\n",
    "        f.write(np.array2string(cm))\n",
    "        f.write(\"\\n\\nClassification Report:\\n\")\n",
    "        f.write(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(\"Saved evaluation report to:\", OUT_REPORT)\n",
    "\n",
    "    # Feature importances plot\n",
    "    fi = pd.Series(best.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    fi.head(20).plot(kind='bar')\n",
    "    plt.title(\"Top 20 Feature Importances (Decision Tree - tuned)\")\n",
    "    plt.ylabel(\"Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_FI_PNG)\n",
    "    plt.close()\n",
    "    print(\"Saved feature importances to:\", OUT_FI_PNG)\n",
    "\n",
    "    # Save tree visualization (may be large)\n",
    "    try:\n",
    "        plt.figure(figsize=(20,12))\n",
    "        plot_tree(best, feature_names=X.columns, class_names=[\"No Disease\",\"Disease\"],\n",
    "                  filled=True, rounded=True, fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUT_TREE_PNG)\n",
    "        plt.close()\n",
    "        print(\"Saved tree visualization to:\", OUT_TREE_PNG)\n",
    "    except Exception as e:\n",
    "        print(\"Could not save tree visualization:\", e)\n",
    "\n",
    "    # Quick console summary\n",
    "    print(\"\\n=== Test set performance (tuned model) ===\")\n",
    "    print(f\"Accuracy: {acc:.4f}  Precision: {prec:.4f}  Recall: {rec:.4f}  F1: {f1:.4f}  ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(\"Done. All outputs in:\", BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e551b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed597f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_engineering_heart.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PATHS ===\n",
    "base_path = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\13 decision tree\\Decision Tree\"\n",
    "file_path = os.path.join(base_path, \"heart_disease.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD DATA ===\n",
    "df = pd.read_excel(file_path, sheet_name=\"Heart_disease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae3cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HANDLE MISSING VALUES ===\n",
    "# Replace missing oldpeak values with median\n",
    "df['oldpeak'] = df['oldpeak'].fillna(df['oldpeak'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0004bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FIX ANOMALIES ===\n",
    "# Replace 0 in trestbps and chol with median (clinically impossible values)\n",
    "for col in ['trestbps', 'chol']:\n",
    "    df[col] = df[col].replace(0, np.nan)\n",
    "    df[col] = df[col].fillna(df[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b73f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONVERT CATEGORICALS ===\n",
    "# Sex → binary\n",
    "df['sex'] = df['sex'].map({'Male':1, 'Female':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c59c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean columns (fbs, exang) → integers\n",
    "for col in ['fbs','exang']:\n",
    "    if df[col].dtype == bool:\n",
    "        df[col] = df[col].astype(int)\n",
    "    elif df[col].dtype == object:   # handle weird cases like 'TURE', 'FALSE'\n",
    "        df[col] = df[col].map({'True':1, 'TURE':1, 'False':0, 'FALSE':0}).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab648cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target → binary (disease present or not)\n",
    "df['target'] = df['num'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical features\n",
    "categorical_cols = ['cp', 'restecg', 'slope', 'thal']\n",
    "df_processed = pd.get_dummies(df, columns=categorical_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d0faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original \"num\"\n",
    "df_processed = df_processed.drop(columns=['num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8fdbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SAVE PROCESSED DATASET ===\n",
    "processed_path = os.path.join(base_path, \"heart_processed.csv\")\n",
    "df_processed.to_csv(processed_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12452793",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature Engineering completed.\")\n",
    "print(\"Processed dataset saved to:\", processed_path)\n",
    "print(\"Final shape:\", df_processed.shape)\n",
    "print(\"Columns:\", df_processed.columns.tolist()[:10], \"...\")  # preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65f3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_evaluation_heart.py\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa0421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PATHS ===\n",
    "BASE_PATH = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\13 decision tree\\Decision Tree\"\n",
    "PROCESSED_CSV = os.path.join(BASE_PATH, \"heart_processed.csv\")\n",
    "MODEL_PATH = os.path.join(BASE_PATH, \"decision_tree_best.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf81b266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === OUTPUT FILES ===\n",
    "EVAL_TXT = os.path.join(BASE_PATH, \"decision_tree_final_evaluation.txt\")\n",
    "CM_PNG = os.path.join(BASE_PATH, \"confusion_matrix_final.png\")\n",
    "ROC_PNG = os.path.join(BASE_PATH, \"roc_curve_final.png\")\n",
    "FI_PNG = os.path.join(BASE_PATH, \"feature_importances_final.png\")\n",
    "TREE_PNG = os.path.join(BASE_PATH, \"decision_tree_final.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ee421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD MODEL & DATA ===\n",
    "print(\"Loading model and data...\")\n",
    "df = pd.read_csv(PROCESSED_CSV)\n",
    "model = joblib.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2875eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PREPARE FEATURES ===\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adcc026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MAKE PREDICTIONS ===\n",
    "y_pred = model.predict(X)\n",
    "y_proba = model.predict_proba(X)[:, 1] if hasattr(model, \"predict_proba\") else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1146982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === METRICS ===\n",
    "acc = accuracy_score(y, y_pred)\n",
    "prec = precision_score(y, y_pred, zero_division=0)\n",
    "rec = recall_score(y, y_pred, zero_division=0)\n",
    "f1 = f1_score(y, y_pred, zero_division=0)\n",
    "roc_auc = roc_auc_score(y, y_proba) if y_proba is not None else float(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a14b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdcd693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SAVE METRICS REPORT ===\n",
    "with open(EVAL_TXT, \"w\") as f:\n",
    "    f.write(\"=== Decision Tree Final Evaluation ===\\n\\n\")\n",
    "    f.write(f\"Accuracy: {acc:.4f}\\nPrecision: {prec:.4f}\\nRecall: {rec:.4f}\\nF1-score: {f1:.4f}\\nROC-AUC: {roc_auc:.4f}\\n\\n\")\n",
    "    f.write(\"Confusion Matrix:\\n\")\n",
    "    f.write(np.array2string(cm))\n",
    "    f.write(\"\\n\\nClassification Report:\\n\")\n",
    "    f.write(classification_report(y, y_pred, zero_division=0))\n",
    "print(\"Saved evaluation metrics to:\", EVAL_TXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82226a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFUSION MATRIX PLOT ===\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix — Decision Tree\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(CM_PNG)\n",
    "plt.close()\n",
    "print(\"Saved confusion matrix plot:\", CM_PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e65412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ROC CURVE ===\n",
    "if y_proba is not None:\n",
    "    fpr, tpr, _ = roc_curve(y, y_proba)\n",
    "    roc_auc_val = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"ROC curve (area = {roc_auc_val:.3f})\")\n",
    "    plt.plot([0,1], [0,1], linestyle='--', lw=1, color='grey')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve — Decision Tree\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ROC_PNG)\n",
    "    plt.close()\n",
    "    print(\"Saved ROC curve:\", ROC_PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e894e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FEATURE IMPORTANCES ===\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=importances.head(15), y=importances.head(15).index)\n",
    "plt.title(\"Top 15 Feature Importances — Decision Tree\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FI_PNG)\n",
    "plt.close()\n",
    "print(\"Saved feature importance chart:\", FI_PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fffad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DECISION TREE STRUCTURE ===\n",
    "plt.figure(figsize=(22,12))\n",
    "plot_tree(model, feature_names=X.columns, class_names=[\"No Disease\", \"Disease\"],\n",
    "          filled=True, rounded=True, fontsize=8)\n",
    "plt.title(\"Decision Tree Structure — Final Model\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(TREE_PNG)\n",
    "plt.close()\n",
    "print(\"Saved decision tree visualization:\", TREE_PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e6f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SUMMARY IN CONSOLE ===\n",
    "print(\"\\n=== Model Performance Summary ===\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "print(\"\\nFeature Importances (Top 10):\")\n",
    "print(importances.head(10))\n",
    "print(\"\\nAll evaluation files are saved in:\", BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a200f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_decision_tree.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report, roc_curve, auc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd46d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- CONFIG -----------------\n",
    "BASE_PATH = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\13 decision tree\\Decision Tree\"\n",
    "RAW_XLSX = os.path.join(BASE_PATH, \"heart_disease.xlsx\")\n",
    "PROCESSED_CSV = os.path.join(BASE_PATH, \"heart_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e972db",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUT = os.path.join(BASE_PATH, \"decision_tree_baseline.pkl\")\n",
    "REPORT_OUT = os.path.join(BASE_PATH, \"decision_tree_evaluation.txt\")\n",
    "CM_PNG = os.path.join(BASE_PATH, \"confusion_matrix_baseline.png\")\n",
    "ROC_PNG = os.path.join(BASE_PATH, \"roc_curve_baseline.png\")\n",
    "TREE_PNG = os.path.join(BASE_PATH, \"decision_tree_baseline.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a03abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37d9a4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def ensure_processed():\n",
    "    \"\"\"If processed CSV missing, create it from raw Excel (simple FE).\"\"\"\n",
    "    if os.path.exists(PROCESSED_CSV):\n",
    "        print(f\"Found processed file: {PROCESSED_CSV}\")\n",
    "        return pd.read_csv(PROCESSED_CSV)\n",
    "    print(\"Processed CSV not found — creating from raw Excel (light feature engineering)...\")\n",
    "    df = pd.read_excel(RAW_XLSX, sheet_name=\"Heart_disease\")\n",
    "    # Basic fixes similar to previous step\n",
    "    df['oldpeak'] = df['oldpeak'].fillna(df['oldpeak'].median())\n",
    "    for col in ['trestbps', 'chol']:\n",
    "        df[col] = df[col].replace(0, np.nan).fillna(df[col].median())\n",
    "    df['sex'] = df['sex'].map({'Male':1, 'Female':0})\n",
    "    for col in ['fbs','exang']:\n",
    "        if df[col].dtype == bool:\n",
    "            df[col] = df[col].astype(int)\n",
    "        else:\n",
    "            df[col] = df[col].map({'True':1,'TURE':1,'False':0,'FALSE':0}).fillna(0).astype(int)\n",
    "    df['target'] = df['num'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    cat_cols = [c for c in ['cp','restecg','slope','thal'] if c in df.columns]\n",
    "    df_processed = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "    if 'num' in df_processed.columns:\n",
    "        df_processed = df_processed.drop(columns=['num'])\n",
    "    df_processed.to_csv(PROCESSED_CSV, index=False)\n",
    "    print(\"Saved processed CSV to:\", PROCESSED_CSV)\n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b44d284",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(df):\n",
    "    # prepare X and y\n",
    "    if 'target' not in df.columns:\n",
    "        raise ValueError(\"No 'target' column found in processed data.\")\n",
    "    X = df.drop(columns=['target'])\n",
    "    y = df['target']\n",
    "\n",
    "    # stratified split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    print(\"Train/test sizes:\", X_train.shape, X_test.shape)\n",
    "\n",
    "    # baseline Decision Tree\n",
    "    clf = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predictions & probs\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_proba = clf.predict_proba(X_test)[:, 1] if hasattr(clf, \"predict_proba\") else None\n",
    "\n",
    "    # metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else float(\"nan\")\n",
    "\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # save model\n",
    "    joblib.dump(clf, MODEL_OUT)\n",
    "\n",
    "    # write evaluation report\n",
    "    with open(REPORT_OUT, \"w\") as f:\n",
    "        f.write(\"Decision Tree — Baseline Evaluation\\n\")\n",
    "        f.write(f\"Train shape: {X_train.shape}\\nTest shape: {X_test.shape}\\n\\n\")\n",
    "        f.write(f\"Accuracy: {acc:.4f}\\nPrecision: {prec:.4f}\\nRecall: {rec:.4f}\\nF1-score: {f1:.4f}\\nROC-AUC: {roc_auc:.4f}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(\"Saved model to:\", MODEL_OUT)\n",
    "    print(\"Saved evaluation report to:\", REPORT_OUT)\n",
    "\n",
    "    # plot confusion matrix\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, [\"No Disease\", \"Disease\"], rotation=45)\n",
    "    plt.yticks(tick_marks, [\"No Disease\", \"Disease\"])\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in np.ndindex(cm.shape):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CM_PNG)\n",
    "    plt.close()\n",
    "    print(\"Saved confusion matrix to:\", CM_PNG)\n",
    "\n",
    "    # ROC curve\n",
    "    if y_proba is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        roc_auc_val = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(6,5))\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'ROC curve (area = {roc_auc_val:.3f})')\n",
    "        plt.plot([0,1], [0,1], linestyle='--', lw=1)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(ROC_PNG)\n",
    "        plt.close()\n",
    "        print(\"Saved ROC curve to:\", ROC_PNG)\n",
    "    else:\n",
    "        print(\"No probability estimates available; skipped ROC curve.\")\n",
    "\n",
    "    # Save a visual of the decision tree (may be large)\n",
    "    try:\n",
    "        plt.figure(figsize=(18,10))\n",
    "        plot_tree(clf, feature_names=X.columns, class_names=[\"No\",\"Yes\"], filled=True, rounded=True, fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(TREE_PNG)\n",
    "        plt.close()\n",
    "        print(\"Saved decision tree visualization to:\", TREE_PNG)\n",
    "    except Exception as e:\n",
    "        print(\"Could not save tree visualization:\", e)\n",
    "\n",
    "    # Print summary to console\n",
    "    print(\"\\n=== Metrics summary ===\")\n",
    "    print(f\"Accuracy: {acc:.4f}  Precision: {prec:.4f}  Recall: {rec:.4f}  F1: {f1:.4f}  ROC-AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca2214",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df_proc = ensure_processed()\n",
    "    train_and_evaluate(df_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a921160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision_tree_assignment.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2331a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5772e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PATHS ===\n",
    "base_path = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\13 decision tree\\Decision Tree\"\n",
    "file_path = os.path.join(base_path, \"heart_disease.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a516906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD DATA ===\n",
    "df = pd.read_excel(file_path, sheet_name=\"Heart_disease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d35552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CLEANING ===\n",
    "# Convert boolean to int\n",
    "for col in ['fbs', 'exang']:\n",
    "    if df[col].dtype == bool:\n",
    "        df[col] = df[col].astype(int)\n",
    "    elif df[col].dtype == object:\n",
    "        df[col] = df[col].map({'True':1, 'TURE':1, 'FALSE':0, 'False':0})  # fix odd strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbd498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex mapping\n",
    "df['sex'] = df['sex'].map({'Male':1, 'Female':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648274ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target binary (num>0 → 1)\n",
    "df['target'] = df['num'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0a2ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical vars\n",
    "ohe_cols = ['cp','restecg','slope','thal']\n",
    "df_processed = pd.get_dummies(df, columns=ohe_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original num column\n",
    "df_processed = df_processed.drop(columns=['num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb0f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRAIN/TEST SPLIT ===\n",
    "X = df_processed.drop(columns=['target'])\n",
    "y = df_processed['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152b46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224229cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === BASELINE MODEL ===\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601718e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef00d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EVALUATION ===\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"Precision\": precision_score(y_test, y_pred),\n",
    "    \"Recall\": recall_score(y_test, y_pred),\n",
    "    \"F1-score\": f1_score(y_test, y_pred),\n",
    "    \"ROC-AUC\": roc_auc_score(y_test, y_proba)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6960d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b877e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SAVE RESULTS ===\n",
    "# Processed dataset\n",
    "processed_path = os.path.join(base_path, \"heart_processed.csv\")\n",
    "df_processed.to_csv(processed_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c0283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_path = os.path.join(base_path, \"decision_tree_model.pkl\")\n",
    "joblib.dump(clf, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b02b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics report\n",
    "report_path = os.path.join(base_path, \"decision_tree_report.txt\")\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(\"=== Decision Tree Evaluation ===\\n\")\n",
    "    for k,v in metrics.items():\n",
    "        f.write(f\"{k}: {v:.4f}\\n\")\n",
    "    f.write(\"\\nClassification Report:\\n\")\n",
    "    f.write(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd647b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix plot\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "cm_path = os.path.join(base_path, \"confusion_matrix.png\")\n",
    "plt.savefig(cm_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f034dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree visualization\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(clf, feature_names=X.columns, class_names=[\"No Disease\",\"Disease\"],\n",
    "          filled=True, rounded=True, fontsize=8)\n",
    "tree_path = os.path.join(base_path, \"decision_tree.png\")\n",
    "plt.savefig(tree_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ad754",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All done! Files saved in:\", base_path)\n",
    "print(\"Processed CSV:\", processed_path)\n",
    "print(\"Model:\", model_path)\n",
    "print(\"Report:\", report_path)\n",
    "print(\"Plots:\", cm_path, \"and\", tree_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e174efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eda_heart_disease.py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099da487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PATHS ===\n",
    "base_path = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\13 decision tree\\Decision Tree\"\n",
    "file_path = os.path.join(base_path, \"heart_disease.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab58aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD DATA ===\n",
    "df = pd.read_excel(file_path, sheet_name=\"Heart_disease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c2e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === BASIC INFO ===\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\n--- Info ---\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing values per column:\\n\", df.isnull().sum())\n",
    "print(\"\\nDuplicate rows:\", df.duplicated().sum())\n",
    "print(\"\\nDescriptive statistics:\\n\", df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be3c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TARGET DISTRIBUTION ===\n",
    "print(\"\\nTarget distribution:\\n\", df['num'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HISTOGRAMS ===\n",
    "numeric_cols = ['age','trestbps','chol','thalch','oldpeak']\n",
    "df[numeric_cols].hist(bins=20, figsize=(12,8))\n",
    "plt.suptitle(\"Histograms of Numeric Features\")\n",
    "plt.savefig(os.path.join(base_path, \"histograms.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105377fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === BOXPLOTS ===\n",
    "plt.figure(figsize=(12,8))\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    plt.subplot(2,3,i)\n",
    "    sns.boxplot(y=df[col])\n",
    "    plt.title(f\"Boxplot of {col}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(base_path, \"boxplots.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1374958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CORRELATION MATRIX ===\n",
    "corr = df[numeric_cols + ['num']].corr()\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.savefig(os.path.join(base_path, \"correlation_matrix.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df73c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEDA completed. Plots saved in:\", base_path)\n",
    "print(\"- histograms.png\")\n",
    "print(\"- boxplots.png\")\n",
    "print(\"- correlation_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8694fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_engineering_heart.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacaaf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PATHS ===\n",
    "base_path = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\13 decision tree\\Decision Tree\"\n",
    "file_path = os.path.join(base_path, \"heart_disease.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e185aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD DATA ===\n",
    "df = pd.read_excel(file_path, sheet_name=\"Heart_disease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841771eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HANDLE MISSING VALUES ===\n",
    "# Replace missing oldpeak values with median\n",
    "df['oldpeak'] = df['oldpeak'].fillna(df['oldpeak'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32d89f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FIX ANOMALIES ===\n",
    "# Replace 0 in trestbps and chol with median (clinically impossible values)\n",
    "for col in ['trestbps', 'chol']:\n",
    "    df[col] = df[col].replace(0, np.nan)\n",
    "    df[col] = df[col].fillna(df[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902f8527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONVERT CATEGORICALS ===\n",
    "# Sex → binary\n",
    "df['sex'] = df['sex'].map({'Male':1, 'Female':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f23212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean columns (fbs, exang) → integers\n",
    "for col in ['fbs','exang']:\n",
    "    if df[col].dtype == bool:\n",
    "        df[col] = df[col].astype(int)\n",
    "    elif df[col].dtype == object:   # handle weird cases like 'TURE', 'FALSE'\n",
    "        df[col] = df[col].map({'True':1, 'TURE':1, 'False':0, 'FALSE':0}).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target → binary (disease present or not)\n",
    "df['target'] = df['num'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4934e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical features\n",
    "categorical_cols = ['cp', 'restecg', 'slope', 'thal']\n",
    "df_processed = pd.get_dummies(df, columns=categorical_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c7922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original \"num\"\n",
    "df_processed = df_processed.drop(columns=['num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c947aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SAVE PROCESSED DATASET ===\n",
    "processed_path = os.path.join(base_path, \"heart_processed.csv\")\n",
    "df_processed.to_csv(processed_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbfff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature Engineering completed.\")\n",
    "print(\"Processed dataset saved to:\", processed_path)\n",
    "print(\"Final shape:\", df_processed.shape)\n",
    "print(\"Columns:\", df_processed.columns.tolist()[:10], \"...\")  # preview"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
