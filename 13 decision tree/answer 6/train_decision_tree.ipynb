{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a200f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_decision_tree.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report, roc_curve, auc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd46d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- CONFIG -----------------\n",
    "BASE_PATH = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\13 decision tree\\Decision Tree\"\n",
    "RAW_XLSX = os.path.join(BASE_PATH, \"heart_disease.xlsx\")\n",
    "PROCESSED_CSV = os.path.join(BASE_PATH, \"heart_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e972db",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUT = os.path.join(BASE_PATH, \"decision_tree_baseline.pkl\")\n",
    "REPORT_OUT = os.path.join(BASE_PATH, \"decision_tree_evaluation.txt\")\n",
    "CM_PNG = os.path.join(BASE_PATH, \"confusion_matrix_baseline.png\")\n",
    "ROC_PNG = os.path.join(BASE_PATH, \"roc_curve_baseline.png\")\n",
    "TREE_PNG = os.path.join(BASE_PATH, \"decision_tree_baseline.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a03abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37d9a4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def ensure_processed():\n",
    "    \"\"\"If processed CSV missing, create it from raw Excel (simple FE).\"\"\"\n",
    "    if os.path.exists(PROCESSED_CSV):\n",
    "        print(f\"Found processed file: {PROCESSED_CSV}\")\n",
    "        return pd.read_csv(PROCESSED_CSV)\n",
    "    print(\"Processed CSV not found — creating from raw Excel (light feature engineering)...\")\n",
    "    df = pd.read_excel(RAW_XLSX, sheet_name=\"Heart_disease\")\n",
    "    # Basic fixes similar to previous step\n",
    "    df['oldpeak'] = df['oldpeak'].fillna(df['oldpeak'].median())\n",
    "    for col in ['trestbps', 'chol']:\n",
    "        df[col] = df[col].replace(0, np.nan).fillna(df[col].median())\n",
    "    df['sex'] = df['sex'].map({'Male':1, 'Female':0})\n",
    "    for col in ['fbs','exang']:\n",
    "        if df[col].dtype == bool:\n",
    "            df[col] = df[col].astype(int)\n",
    "        else:\n",
    "            df[col] = df[col].map({'True':1,'TURE':1,'False':0,'FALSE':0}).fillna(0).astype(int)\n",
    "    df['target'] = df['num'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    cat_cols = [c for c in ['cp','restecg','slope','thal'] if c in df.columns]\n",
    "    df_processed = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "    if 'num' in df_processed.columns:\n",
    "        df_processed = df_processed.drop(columns=['num'])\n",
    "    df_processed.to_csv(PROCESSED_CSV, index=False)\n",
    "    print(\"Saved processed CSV to:\", PROCESSED_CSV)\n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b44d284",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(df):\n",
    "    # prepare X and y\n",
    "    if 'target' not in df.columns:\n",
    "        raise ValueError(\"No 'target' column found in processed data.\")\n",
    "    X = df.drop(columns=['target'])\n",
    "    y = df['target']\n",
    "\n",
    "    # stratified split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    print(\"Train/test sizes:\", X_train.shape, X_test.shape)\n",
    "\n",
    "    # baseline Decision Tree\n",
    "    clf = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predictions & probs\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_proba = clf.predict_proba(X_test)[:, 1] if hasattr(clf, \"predict_proba\") else None\n",
    "\n",
    "    # metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else float(\"nan\")\n",
    "\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # save model\n",
    "    joblib.dump(clf, MODEL_OUT)\n",
    "\n",
    "    # write evaluation report\n",
    "    with open(REPORT_OUT, \"w\") as f:\n",
    "        f.write(\"Decision Tree — Baseline Evaluation\\n\")\n",
    "        f.write(f\"Train shape: {X_train.shape}\\nTest shape: {X_test.shape}\\n\\n\")\n",
    "        f.write(f\"Accuracy: {acc:.4f}\\nPrecision: {prec:.4f}\\nRecall: {rec:.4f}\\nF1-score: {f1:.4f}\\nROC-AUC: {roc_auc:.4f}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(\"Saved model to:\", MODEL_OUT)\n",
    "    print(\"Saved evaluation report to:\", REPORT_OUT)\n",
    "\n",
    "    # plot confusion matrix\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, [\"No Disease\", \"Disease\"], rotation=45)\n",
    "    plt.yticks(tick_marks, [\"No Disease\", \"Disease\"])\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in np.ndindex(cm.shape):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CM_PNG)\n",
    "    plt.close()\n",
    "    print(\"Saved confusion matrix to:\", CM_PNG)\n",
    "\n",
    "    # ROC curve\n",
    "    if y_proba is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        roc_auc_val = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(6,5))\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'ROC curve (area = {roc_auc_val:.3f})')\n",
    "        plt.plot([0,1], [0,1], linestyle='--', lw=1)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(ROC_PNG)\n",
    "        plt.close()\n",
    "        print(\"Saved ROC curve to:\", ROC_PNG)\n",
    "    else:\n",
    "        print(\"No probability estimates available; skipped ROC curve.\")\n",
    "\n",
    "    # Save a visual of the decision tree (may be large)\n",
    "    try:\n",
    "        plt.figure(figsize=(18,10))\n",
    "        plot_tree(clf, feature_names=X.columns, class_names=[\"No\",\"Yes\"], filled=True, rounded=True, fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(TREE_PNG)\n",
    "        plt.close()\n",
    "        print(\"Saved decision tree visualization to:\", TREE_PNG)\n",
    "    except Exception as e:\n",
    "        print(\"Could not save tree visualization:\", e)\n",
    "\n",
    "    # Print summary to console\n",
    "    print(\"\\n=== Metrics summary ===\")\n",
    "    print(f\"Accuracy: {acc:.4f}  Precision: {prec:.4f}  Recall: {rec:.4f}  F1: {f1:.4f}  ROC-AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca2214",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df_proc = ensure_processed()\n",
    "    train_and_evaluate(df_proc)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
