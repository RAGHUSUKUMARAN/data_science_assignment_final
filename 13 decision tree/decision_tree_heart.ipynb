{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97ced0b2",
   "metadata": {},
   "source": [
    "# Decision Tree Classification — Heart Disease Dataset\n",
    "\n",
    "This notebook walks through EDA, preprocessing, Decision Tree training, hyperparameter tuning, evaluation, and interpretation using `sklearn.tree.plot_tree` for visualization.\n",
    "\n",
    "Change `file_path` in the data-loading cell if you run the notebook locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43d214f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports ready\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, confusion_matrix, RocCurveDisplay)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,6)\n",
    "print('Imports ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fa0b01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: D:\\NEW DATA SCIENCE ASSIGNMENT\\8.Decision Tree\\heart_disease.xlsx\n",
      "Shape: (12, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Age in years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gender</td>\n",
       "      <td>Gender ; Male - 1, Female -0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cp</td>\n",
       "      <td>Chest pain type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>Resting blood pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chol</td>\n",
       "      <td>cholesterol measure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fbs</td>\n",
       "      <td>(fasting blood sugar &gt; 120 mg/dl) (1 = true; 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age                                       Age in years\n",
       "0    Gender                       Gender ; Male - 1, Female -0\n",
       "1        cp                                    Chest pain type\n",
       "2  trestbps                             Resting blood pressure\n",
       "3      chol                                cholesterol measure\n",
       "4       fbs  (fasting blood sugar > 120 mg/dl) (1 = true; 0..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset (change file_path if needed)\n",
    "file_path = r'D:\\NEW DATA SCIENCE ASSIGNMENT\\8.Decision Tree\\heart_disease.xlsx'  # change this to your local path if needed\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(file_path)\n",
    "    print('Loaded:', file_path)\n",
    "except Exception as e:\n",
    "    raise SystemExit(f\"Could not load the dataset at {file_path}: {e}\")\n",
    "\n",
    "print('Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675662f9",
   "metadata": {},
   "source": [
    "## 1 — Exploratory Data Analysis (EDA)\n",
    "\n",
    "Inspect structure, missing values, summary statistics, class balance, and correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d2bfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   age           12 non-null     object\n",
      " 1   Age in years  12 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 324.0+ bytes\n",
      "None\n",
      "\n",
      "Missing values per column:\n",
      " age             0\n",
      "Age in years    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Gender</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age in years</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Gender ; Male - 1, Female -0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count unique                           top freq\n",
       "age             12     12                        Gender    1\n",
       "Age in years    12     12  Gender ; Male - 1, Female -0    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate target columns found: []\n",
      "Final candidate targets: []\n",
      "No obvious binary target found. You will need to set the target column manually in the next cell.\n"
     ]
    }
   ],
   "source": [
    "# Basic EDA\n",
    "print(df.info())\n",
    "print('\\nMissing values per column:\\n', df.isnull().sum())\n",
    "\n",
    "display(df.describe().T)\n",
    "\n",
    "# Class distribution: try to detect a binary target column\n",
    "possible_targets = [c for c in df.columns if c.lower() in ('target','outcome','disease','heartdisease','hd','diagnosis','num')]\n",
    "print('Candidate target columns found:', possible_targets)\n",
    "\n",
    "# If none found, try numeric columns with only 0/1 values\n",
    "if not possible_targets:\n",
    "    for c in df.select_dtypes(include=[np.number]).columns:\n",
    "        unique_vals = df[c].dropna().unique()\n",
    "        if set(unique_vals).issubset({0,1}):\n",
    "            possible_targets.append(c)\n",
    "print('Final candidate targets:', possible_targets)\n",
    "\n",
    "# Show distribution for top candidate (not applied yet)\n",
    "if possible_targets:\n",
    "    tgt = possible_targets[0]\n",
    "    print(f\"Using candidate target column: {tgt}\")\n",
    "    print(df[tgt].value_counts(dropna=False))\n",
    "else:\n",
    "    print('No obvious binary target found. You will need to set the target column manually in the next cell.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0547b218",
   "metadata": {},
   "source": [
    "## 2 — Feature Engineering & Preprocessing\n",
    "\n",
    "- Identify the target column (auto-detected if possible).  \n",
    "- Handle missing values and encode categorical variables.  \n",
    "- Scale numeric features when appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "468ce0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected target column: target\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Target column 'target' not found. Edit `target_col` to the correct column name.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m Target column 'target' not found. Edit `target_col` to the correct column name.\n"
     ]
    }
   ],
   "source": [
    "# === Preprocessing ===\n",
    "# Auto-detect target (falls back to manual assignment)\n",
    "candidate_targets = [c for c in df.columns if c.lower() in ('target','outcome','disease','heartdisease','hd','diagnosis','num')]\n",
    "if not candidate_targets:\n",
    "    # try 0/1 numeric detection\n",
    "    for c in df.select_dtypes(include=[np.number]).columns:\n",
    "        uv = df[c].dropna().unique()\n",
    "        if set(uv).issubset({0,1}):\n",
    "            candidate_targets.append(c)\n",
    "\n",
    "if candidate_targets:\n",
    "    target_col = candidate_targets[0]\n",
    "else:\n",
    "    # If auto-detection fails, set target_col manually here\n",
    "    target_col = 'target'  # <-- change this to your known target column name\n",
    "\n",
    "print('Selected target column:', target_col)\n",
    "\n",
    "# Basic cleaning: drop rows where target is missing\n",
    "df = df.copy()\n",
    "if target_col not in df.columns:\n",
    "    raise SystemExit(f\"Target column '{target_col}' not found. Edit `target_col` to the correct column name.\")\n",
    "\n",
    "print('Rows before dropping missing target:', df.shape[0])\n",
    "df = df.dropna(subset=[target_col])\n",
    "print('Rows after dropping missing target:', df.shape[0])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Identify categorical columns (object or category dtypes)\n",
    "cat_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print('Categorical columns:', cat_cols)\n",
    "print('Numeric columns:', num_cols)\n",
    "\n",
    "# Simple encoding: one-hot encode categoricals (drop_first to avoid collinearity)\n",
    "if cat_cols:\n",
    "    X = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Impute numeric missing values with median\n",
    "for c in num_cols:\n",
    "    if c in X.columns and X[c].isnull().any():\n",
    "        X[c].fillna(X[c].median(), inplace=True)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "# Only scale columns that still exist (num_cols may overlap with get_dummies modifications)\n",
    "num_cols_existing = [c for c in num_cols if c in X.columns]\n",
    "if num_cols_existing:\n",
    "    X[num_cols_existing] = scaler.fit_transform(X[num_cols_existing])\n",
    "\n",
    "print('Processed feature shape:', X.shape)\n",
    "print('Sample processed features:')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "233e9410-cc16-45c2-ac98-ca8d6e5a5283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'Age in years']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56058a",
   "metadata": {},
   "source": [
    "## 3 — Train/Test Split and Baseline Decision Tree\n",
    "\n",
    "Split the data 80/20 and train a baseline Decision Tree with default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6649797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n",
    "\n",
    "# Baseline Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print('Baseline Decision Tree performance:')\n",
    "print(f'Accuracy: {acc:.4f}  Precision: {prec:.4f}  Recall: {rec:.4f}  F1: {f1:.4f}')\n",
    "\n",
    "# ROC-AUC if possible\n",
    "if hasattr(dt, 'predict_proba'):\n",
    "    y_proba = dt.predict_proba(X_test)[:,1]\n",
    "    try:\n",
    "        roc = roc_auc_score(y_test, y_proba)\n",
    "        print(f'ROC-AUC: {roc:.4f}')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('\\nConfusion matrix:\\n', cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdef9fe",
   "metadata": {},
   "source": [
    "## 4 — Hyperparameter Tuning (GridSearchCV)\n",
    "\n",
    "Tune max_depth, min_samples_split, and criterion using 5-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4549877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 3, 5, 7, 9],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "gscv = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "gscv.fit(X_train, y_train)\n",
    "print('Best params:', gscv.best_params_)\n",
    "print('Best CV score (f1):', gscv.best_score_)\n",
    "\n",
    "best_dt = gscv.best_estimator_\n",
    "best_dt.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate best model\n",
    "y_pred_best = best_dt.predict(X_test)\n",
    "acc_b = accuracy_score(y_test, y_pred_best)\n",
    "prec_b = precision_score(y_test, y_pred_best, zero_division=0)\n",
    "rec_b = recall_score(y_test, y_pred_best, zero_division=0)\n",
    "f1_b = f1_score(y_test, y_pred_best, zero_division=0)\n",
    "print('\\nTuned Decision Tree performance:')\n",
    "print(f'Accuracy: {acc_b:.4f}  Precision: {prec_b:.4f}  Recall: {rec_b:.4f}  F1: {f1_b:.4f}')\n",
    "\n",
    "if hasattr(best_dt, 'predict_proba'):\n",
    "    try:\n",
    "        roc_b = roc_auc_score(y_test, best_dt.predict_proba(X_test)[:,1])\n",
    "        print(f'ROC-AUC: {roc_b:.4f}')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "cm_b = confusion_matrix(y_test, y_pred_best)\n",
    "print('\\nConfusion matrix (tuned):\\n', cm_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17291d12",
   "metadata": {},
   "source": [
    "## 5 — Model Interpretation & Visualization\n",
    "\n",
    "Plot the decision tree and show feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ab22f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the tree (limit max depth in the plot for readability)\n",
    "plt.figure(figsize=(20,12))\n",
    "plot_tree(best_dt, feature_names=X.columns, class_names=[str(c) for c in np.unique(y)], filled=True, rounded=True)\n",
    "plt.title('Decision Tree (full)')\n",
    "plt.show()\n",
    "\n",
    "# Feature importances\n",
    "fi = pd.Series(best_dt.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print('Top 20 feature importances:')\n",
    "display(fi.head(20))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "fi.head(20).plot(kind='bar')\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "if hasattr(best_dt, 'predict_proba'):\n",
    "    try:\n",
    "        RocCurveDisplay.from_estimator(best_dt, X_test, y_test)\n",
    "        plt.show()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_best), annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (tuned)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d1f18",
   "metadata": {},
   "source": [
    "## Interview Questions & Answers\n",
    "\n",
    "1. What are some common hyperparameters of decision tree models, and how do they affect the model's performance?\n",
    "\n",
    "- max_depth: maximum depth of the tree. Smaller values reduce overfitting but may underfit. Larger values allow complex rules but risk overfitting.\n",
    "- min_samples_split: minimum number of samples required to split an internal node. Larger values make the tree more conservative.\n",
    "- min_samples_leaf: minimum number of samples required to be at a leaf node. Increasing it reduces variance.\n",
    "- criterion: the function to measure the quality of a split (e.g., 'gini' or 'entropy'). Different criteria can produce slightly different trees.\n",
    "- max_features: number of features to consider when looking for the best split. Limiting can reduce variance and speed up training.\n",
    "\n",
    "2. What is the difference between Label encoding and One-hot encoding?\n",
    "\n",
    "- Label encoding assigns each category a unique integer label. It is compact but introduces ordinal relationships between categories which may be inappropriate.\n",
    "- One-hot encoding creates binary columns for each category level; it does not assume any ordering and is typically safer for nominal categorical data but increases dimensionality.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
