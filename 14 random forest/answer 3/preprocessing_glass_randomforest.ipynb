{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfaf03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing_glass_randomforest_safe.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PATH SETUP ===\n",
    "base_path = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\14 random forest\\Random Forest\"\n",
    "file_path = os.path.join(base_path, \"glass.xlsx\")\n",
    "processed_path = os.path.join(base_path, \"glass_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47edc336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD DATA ===\n",
    "df = pd.read_excel(file_path, sheet_name=\"glass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ Dataset loaded successfully.\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\n--- Missing Values Check ---\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cdcddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 1️⃣ HANDLE MISSING VALUES\n",
    "# =========================================================\n",
    "if df.isnull().sum().sum() == 0:\n",
    "    print(\"\\nNo missing values found — no imputation needed.\")\n",
    "else:\n",
    "    print(\"\\nMissing values detected. Applying median imputation.\")\n",
    "    df = df.fillna(df.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108e3697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 2️⃣ ENCODE CATEGORICAL VARIABLES\n",
    "# =========================================================\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "if len(cat_cols) > 0:\n",
    "    print(\"\\nCategorical columns found:\", list(cat_cols))\n",
    "    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "else:\n",
    "    print(\"\\nNo categorical columns — encoding not required.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47732e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 3️⃣ FEATURE SCALING\n",
    "# =========================================================\n",
    "X = df.drop(columns=['Type'])\n",
    "y = df['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868b21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7b0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFeature scaling (Standardization) applied successfully.\")\n",
    "print(\"Mean of scaled features (approx):\\n\", X_scaled.mean().round(3))\n",
    "print(\"Std dev of scaled features (approx):\\n\", X_scaled.std().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656fb2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 4️⃣ HANDLE IMBALANCED DATA (try SMOTE, else fallback)\n",
    "# =========================================================\n",
    "print(\"\\n--- Target Distribution Before Balancing ---\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_smote = False\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    use_smote = True\n",
    "except Exception as e:\n",
    "    print(\"\\nNote: imbalanced-learn / SMOTE not available or failed to import.\")\n",
    "    print(\"Reason:\", str(e))\n",
    "    print(\"Proceeding without SMOTE (data will remain unbalanced).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c10c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_smote:\n",
    "    # Try SMOTE, but protect against runtime errors (e.g., too few samples for k_neighbors)\n",
    "    try:\n",
    "        # For small classes, set k_neighbors to min(3, n_min_class-1)\n",
    "        from collections import Counter\n",
    "        class_counts = Counter(y)\n",
    "        n_min = min(class_counts.values())\n",
    "        k_neighbors = 3\n",
    "        if n_min <= 3:\n",
    "            k_neighbors = max(1, n_min - 1)  # SMOTE requires k_neighbors < n_min, adjust down safely\n",
    "        smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
    "        X_bal, y_bal = smote.fit_resample(X_scaled, y)\n",
    "        print(\"\\nSMOTE applied successfully.\")\n",
    "        print(\"--- Target Distribution After SMOTE Balancing ---\")\n",
    "        print(pd.Series(y_bal).value_counts())\n",
    "        final_X, final_y = X_bal, y_bal\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"SMOTE failed at fit_resample: {e}. Proceeding without SMOTE.\")\n",
    "        final_X, final_y = X_scaled, y\n",
    "else:\n",
    "    final_X, final_y = X_scaled, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5570372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# SAVE PROCESSED DATA\n",
    "# =========================================================\n",
    "processed_df = pd.concat([pd.DataFrame(final_X, columns=X.columns), pd.Series(final_y, name=\"Type\")], axis=1)\n",
    "processed_df.to_csv(processed_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f83453",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n✅ Data Preprocessing Completed Successfully.\")\n",
    "print(\"Processed file saved as:\", processed_path)\n",
    "print(\"Final shape:\", processed_df.shape)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
