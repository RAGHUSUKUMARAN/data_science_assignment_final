{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d9da9e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# Clustering Analysis — EastWestAirlines\n",
    "# Author: Maddy\n",
    "# Folder: D:\\DATA SCIENCE\\ASSIGNMENTS\\8 clustering\\Clustering\\files\n",
    "# Notebook: EDA → Preprocessing → KMeans / Agglomerative / DBSCAN → Evaluation → Save outputs\n",
    "\n",
    "# %%\n",
    "# 1. Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set(style='whitegrid')\n",
    "    HAS_SEABORN = True\n",
    "except Exception:\n",
    "    HAS_SEABORN = False\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "print('imports ok')\n",
    "\n",
    "# %%\n",
    "# 2. Paths & load\n",
    "BASE = Path(r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\8 clustering\\Clustering\\files\")\n",
    "DATA_CSV = BASE / \"EastWestAirlines.csv\"  # update if different\n",
    "OUT_DIR = BASE\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not DATA_CSV.exists():\n",
    "    raise FileNotFoundError(f\"Data file not found at {DATA_CSV}. Put the CSV there or edit DATA_CSV.\")\n",
    "\n",
    "print('Loading:', DATA_CSV)\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "print('shape:', df.shape)\n",
    "print('columns:', df.columns.tolist())\n",
    "\n",
    "# %%\n",
    "# 3. Quick EDA\n",
    "print('\\nMissing values per column:\\n', df.isnull().sum())\n",
    "print('\\nNumeric dtypes:')\n",
    "print(df.select_dtypes(include=[np.number]).columns.tolist())\n",
    "\n",
    "df.describe().T.to_csv(OUT_DIR / 'descriptive_stats.csv')\n",
    "print('Saved descriptive_stats.csv')\n",
    "\n",
    "# Histograms (sample if many columns)\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "plt.figure(figsize=(12,8))\n",
    "df[num_cols].hist(bins=30, figsize=(12,8))\n",
    "plt.suptitle('Histograms (raw)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / 'histograms_raw.png', dpi=150)\n",
    "plt.close()\n",
    "print('Saved histograms_raw.png')\n",
    "\n",
    "# Boxplots\n",
    "plt.figure(figsize=(12,6))\n",
    "if HAS_SEABORN:\n",
    "    sns.boxplot(data=df[num_cols], orient='h')\n",
    "else:\n",
    "    df[num_cols].plot(kind='box', vert=False, figsize=(12,6))\n",
    "plt.title('Boxplots (raw)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / 'boxplots_raw.png', dpi=150)\n",
    "plt.close()\n",
    "print('Saved boxplots_raw.png')\n",
    "\n",
    "# %%\n",
    "# 4. Preprocessing: drop ID, remove outliers via IQR, scale\n",
    "if 'ID#' in df.columns:\n",
    "    df = df.drop(columns=['ID#'])\n",
    "\n",
    "# ensure numeric-only features for clustering (keep Award? aside if present)\n",
    "label_col = None\n",
    "for possible in ['Award?', 'Award', 'award', 'Target']:\n",
    "    if possible in df.columns:\n",
    "        label_col = possible\n",
    "        break\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if label_col in numeric_cols:\n",
    "    numeric_cols.remove(label_col)\n",
    "\n",
    "print('Numeric features used for clustering:', numeric_cols)\n",
    "\n",
    "# Remove outliers by iteratively applying IQR filter across numeric columns\n",
    "def remove_outliers_iqr(df_in, cols):\n",
    "    df_out = df_in.copy()\n",
    "    for col in cols:\n",
    "        Q1 = df_out[col].quantile(0.25)\n",
    "        Q3 = df_out[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        df_out = df_out[(df_out[col] >= lower) & (df_out[col] <= upper)]\n",
    "    return df_out\n",
    "\n",
    "print('Original rows:', df.shape[0])\n",
    "df_no_out = remove_outliers_iqr(df, numeric_cols)\n",
    "print('After IQR outlier removal rows:', df_no_out.shape[0])\n",
    "\n",
    "# scale\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_no_out[numeric_cols].fillna(df_no_out[numeric_cols].median()))\n",
    "scaled_df = pd.DataFrame(X_scaled, columns=numeric_cols, index=df_no_out.index)\n",
    "scaled_df.to_csv(OUT_DIR / 'eastwest_scaled_numeric.csv', index=False)\n",
    "print('Saved eastwest_scaled_numeric.csv')\n",
    "\n",
    "# %%\n",
    "# 5. PCA for visualization\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "print('PCA explained variance (first 2):', pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "if label_col:\n",
    "    labels = df_no_out[label_col].astype(str).values\n",
    "    uniq = np.unique(labels)\n",
    "    cmap = plt.cm.tab10\n",
    "    color_map = {v:i for i,v in enumerate(uniq)}\n",
    "    colors = [color_map[v] for v in labels]\n",
    "    plt.scatter(X_pca[:,0], X_pca[:,1], c=colors, s=10, alpha=0.6)\n",
    "    # legend\n",
    "    handles = [plt.Line2D([0],[0], marker='o', color='w', label=str(u), markerfacecolor=plt.cm.tab10(i), markersize=6) for i,u in enumerate(uniq)]\n",
    "    plt.legend(handles=handles, title=label_col)\n",
    "else:\n",
    "    plt.scatter(X_pca[:,0], X_pca[:,1], alpha=0.6, s=10)\n",
    "\n",
    "plt.xlabel('PC1'); plt.ylabel('PC2'); plt.title('PCA (2D)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / 'pca_2d.png', dpi=150)\n",
    "plt.close()\n",
    "print('Saved pca_2d.png')\n",
    "\n",
    "# %%\n",
    "# 6. KMeans: elbow + silhouette sweep\n",
    "from collections import defaultdict\n",
    "results_kmeans = []\n",
    "for k in range(2,11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "    results_kmeans.append((k, sil))\n",
    "\n",
    "k_vals, sils = zip(*results_kmeans)\n",
    "pd.DataFrame(results_kmeans, columns=['k','silhouette']).to_csv(OUT_DIR / 'kmeans_silhouette.csv', index=False)\n",
    "print('KMeans silhouette results saved to kmeans_silhouette.csv')\n",
    "\n",
    "# choose best k by silhouette\n",
    "best_k, best_sil = max(results_kmeans, key=lambda t: t[1])\n",
    "print('KMeans: best k by silhouette in range 2-10:', best_k, 'silhouette:', best_sil)\n",
    "\n",
    "# fit best k and save cluster means\n",
    "kmeans_best = KMeans(n_clusters=best_k, random_state=42, n_init=10).fit(X_scaled)\n",
    "labels_k = kmeans_best.labels_\n",
    "scaled_df['kmeans_cluster'] = labels_k\n",
    "cluster_means = scaled_df.groupby('kmeans_cluster').mean()\n",
    "cluster_means.reset_index().to_csv(OUT_DIR / f'kmeans_k{best_k}_cluster_feature_means.csv', index=False)\n",
    "print('Saved cluster means for kmeans_k', best_k)\n",
    "\n",
    "# PCA scatter colored by KMeans\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=labels_k, cmap='tab10', s=10, alpha=0.7)\n",
    "plt.title(f'KMeans k={best_k} PCA')\n",
    "plt.savefig(OUT_DIR / f'kmeans_k{best_k}_pca.png', dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# silhouette score\n",
    "print('KMeans silhouette:', best_sil)\n",
    "\n",
    "# %%\n",
    "# 7. Agglomerative clustering experiments\n",
    "agg_results = {}\n",
    "linkages = ['ward','complete','average']\n",
    "for link in linkages:\n",
    "    # skip ward if not compatible with metric other than euclidean (we use default)\n",
    "    agg = AgglomerativeClustering(n_clusters=best_k, linkage=link)\n",
    "    labels_a = agg.fit_predict(X_scaled)\n",
    "    try:\n",
    "        sil = silhouette_score(X_scaled, labels_a)\n",
    "    except Exception:\n",
    "        sil = np.nan\n",
    "    agg_results[link] = (labels_a, sil)\n",
    "    print(f'Agglomerative ({link}) silhouette: {sil}')\n",
    "    # save cluster means\n",
    "    df_temp = pd.DataFrame(X_scaled, columns=numeric_cols)\n",
    "    df_temp['cluster'] = labels_a\n",
    "    df_temp.groupby('cluster').mean().reset_index().to_csv(OUT_DIR / f'agg_{link}_cluster_feature_means.csv', index=False)\n",
    "\n",
    "# pick best linkage by silhouette\n",
    "best_link, best_link_val = max(agg_results.items(), key=lambda kv: (kv[1][1] if not np.isnan(kv[1][1]) else -999))\n",
    "print('Best agglomerative linkage:', best_link, 'silhouette:', best_link_val[1])\n",
    "\n",
    "# PCA scatter color by best agg\n",
    "labels_agg_best = agg_results[best_link][0]\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=labels_agg_best, cmap='tab10', s=10, alpha=0.7)\n",
    "plt.title(f'Agglomerative ({best_link}) PCA')\n",
    "plt.savefig(OUT_DIR / f'agg_{best_link}_pca.png', dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# %%\n",
    "# 8. DBSCAN parameter sweep (eps, min_samples)\n",
    "dbscan_results = []\n",
    "eps_vals = [0.3, 0.5, 0.7, 0.9, 1.1]\n",
    "min_samples_vals = [4,6,8]\n",
    "for eps in eps_vals:\n",
    "    for ms in min_samples_vals:\n",
    "        db = DBSCAN(eps=eps, min_samples=ms)\n",
    "        lab = db.fit_predict(X_scaled)\n",
    "        # number of clusters (exclude noise label -1)\n",
    "        n_clusters = len(set(lab)) - (1 if -1 in lab else 0)\n",
    "        # require at least 2 clusters for silhouette\n",
    "        if n_clusters >= 2:\n",
    "            sil = silhouette_score(X_scaled, lab)\n",
    "        else:\n",
    "            sil = -999\n",
    "        noise = np.sum(lab == -1)\n",
    "        dbscan_results.append({'eps':eps, 'min_samples':ms, 'n_clusters':n_clusters, 'silhouette':sil, 'noise':int(noise)})\n",
    "\n",
    "pd.DataFrame(dbscan_results).to_csv(OUT_DIR / 'dbscan_sweep.csv', index=False)\n",
    "print('Saved dbscan_sweep.csv')\n",
    "\n",
    "# Best DBSCAN by silhouette\n",
    "df_db = pd.DataFrame(dbscan_results)\n",
    "best_db = df_db.loc[df_db['silhouette'].idxmax()]\n",
    "print('Best DBSCAN:', best_db.to_dict())\n",
    "\n",
    "# fit best DBSCAN and save cluster means\n",
    "db_best = DBSCAN(eps=float(best_db.eps), min_samples=int(best_db.min_samples)).fit(X_scaled)\n",
    "labels_db = db_best.labels_\n",
    "pd.DataFrame(X_scaled, columns=numeric_cols).assign(cluster=labels_db).groupby('cluster').mean().reset_index().to_csv(OUT_DIR / f\"dbscan_eps{best_db.eps}_ms{int(best_db.min_samples)}_cluster_feature_means.csv\", index=False)\n",
    "\n",
    "# PCA scatter for DBSCAN\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=labels_db, cmap='tab10', s=10, alpha=0.7)\n",
    "plt.title(f'DBSCAN eps={best_db.eps} ms={best_db.min_samples}')\n",
    "plt.savefig(OUT_DIR / f'dbscan_eps{best_db.eps}_ms{int(best_db.min_samples)}_pca.png', dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# %%\n",
    "# 9. Summary outputs saved\n",
    "print('\\n--- FINAL SUMMARY ---')\n",
    "print(f'KMeans k={best_k} silhouette={best_sil:.4f}')\n",
    "print('Agglomerative best linkage:', best_link, 'silhouette:', agg_results[best_link][1])\n",
    "print('DBSCAN best:', best_db.to_dict())\n",
    "\n",
    "print('\\nSaved outputs to:', OUT_DIR)\n",
    "print('Files created include: eastwest_scaled_numeric.csv, descriptive_stats.csv, histograms_raw.png, boxplots_raw.png, correlation_heatmap.png (if computed), pca_2d.png, kmeans and agg and dbscan CSVs and PCA plots')\n",
    "\n",
    "# End of notebook\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
