{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec2b8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38d294",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load your dataset (from the \"data\" sheet)\n",
    "file_path = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\8 clustering\\Clustering\\EastWestAirlines.csv\"\n",
    "df = pd.read_csv(r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\8 clustering\\Clustering\\EastWestAirlines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e104cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID# column if present\n",
    "if \"ID#\" in df.columns:\n",
    "    df = df.drop(columns=[\"ID#\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45e18d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cefc37b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Step 1: Handle missing values (none in this dataset, but good to keep)\n",
    "print(\"\\nMissing values per column:\\n\", df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7028ba5c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Step 2: Outlier removal using IQR\n",
    "def remove_outliers_iqr(data):\n",
    "    df_out = data.copy()\n",
    "    for col in df_out.select_dtypes(include=[np.number]).columns:\n",
    "        Q1 = df_out[col].quantile(0.25)\n",
    "        Q3 = df_out[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        df_out = df_out[(df_out[col] >= lower) & (df_out[col] <= upper)]\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d749fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers = remove_outliers_iqr(df)\n",
    "print(\"\\nAfter outlier removal:\", df_no_outliers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a41e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Scaling numeric features\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_no_outliers.drop(columns=[\"Award?\"]))\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=df_no_outliers.drop(columns=[\"Award?\"]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep Award? column separately (optional for clustering)\n",
    "df_scaled[\"Award?\"] = df_no_outliers[\"Award?\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a81aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed dataset to the same folder\n",
    "output_path = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\8 clustering\\Clustering\\EastWestAirlines_Preprocessed.xlsx\"\n",
    "df_scaled.to_excel(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a532fefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nPreprocessed dataset saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4073873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b44dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d5b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional nicer plots if seaborn is available\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    HAS_SEABORN = True\n",
    "except Exception:\n",
    "    HAS_SEABORN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79613d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be3ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- CONFIG --------------\n",
    "# Change this to your actual path if needed.\n",
    "# file_path = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\8 clustering\\Clustering\\EastWestAirlines.csv\"\n",
    "# If you prefer CSV, comment above and uncomment below:\n",
    "file_path = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\8 clustering\\Clustering\\EastWestAirlines.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6016f7b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "out_folder = Path(file_path).parent  # save outputs next to the data file\n",
    "os.makedirs(out_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a4f8a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# -------------- Load data --------------\n",
    "def load_data(fp):\n",
    "    fp = Path(fp)\n",
    "    if fp.suffix.lower() in [\".xlsx\", \".xls\"]:\n",
    "        # try to be explicit about engine to avoid pandas warnings\n",
    "        try:\n",
    "            df = pd.read_excel(fp, sheet_name=\"data\", engine=\"openpyxl\")\n",
    "        except Exception as e:\n",
    "            # fallback: try without engine (pandas will try its default)\n",
    "            print(\"Warning: read_excel with engine failed:\", e)\n",
    "            df = pd.read_excel(fp, sheet_name=\"data\")\n",
    "    elif fp.suffix.lower() == \".csv\":\n",
    "        df = pd.read_csv(fp)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type: \" + str(fp.suffix))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b400bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data from:\", file_path)\n",
    "df = load_data(file_path)\n",
    "print(\"Raw shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c28628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If ID# exists, drop it (identifier)\n",
    "if 'ID#' in df.columns:\n",
    "    df = df.drop(columns=['ID#'])\n",
    "    print(\"Dropped ID# column. New shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e121363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Quick checks --------------\n",
    "print(\"\\nMissing values per column:\\n\", df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea31f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only numeric features for clustering/EDA visuals (but keep Award? separately)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(\"\\nNumeric columns detected:\", numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa377352",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(numeric_cols) < 2:\n",
    "    raise SystemExit(\"Not enough numeric columns found for EDA/Clustering. Please check the data sheet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f5556",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df[numeric_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166065ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Descriptive statistics --------------\n",
    "desc = df_num.describe().T\n",
    "desc_file = out_folder / \"eastwest_descriptive_stats.csv\"\n",
    "desc.to_csv(desc_file)\n",
    "print(f\"\\nDescriptive statistics saved to: {desc_file}\")\n",
    "print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3401fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Histograms (before scaling) --------------\n",
    "plt.figure(figsize=(12, 8))\n",
    "df_num.hist(bins=30, figsize=(12, 8))\n",
    "plt.suptitle(\"Histograms of numeric features (raw)\", y=0.95)\n",
    "plt.tight_layout()\n",
    "hist_file = out_folder / \"histograms_raw.png\"\n",
    "plt.savefig(hist_file, dpi=150)\n",
    "plt.close()\n",
    "print(\"Saved histograms to:\", hist_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a79c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Boxplots (detect outliers visually) --------------\n",
    "plt.figure(figsize=(12, 6))\n",
    "if HAS_SEABORN:\n",
    "    sns.boxplot(data=df_num, orient=\"h\")\n",
    "else:\n",
    "    df_num.plot(kind=\"box\", vert=False, figsize=(12,6))\n",
    "plt.title(\"Boxplots of numeric features (raw)\")\n",
    "plt.tight_layout()\n",
    "box_file = out_folder / \"boxplots_raw.png\"\n",
    "plt.savefig(box_file, dpi=150)\n",
    "plt.close()\n",
    "print(\"Saved boxplots to:\", box_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723fe875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Correlation heatmap --------------\n",
    "corr = df_num.corr()\n",
    "corr_file_csv = out_folder / \"eastwest_correlation.csv\"\n",
    "corr.to_csv(corr_file_csv)\n",
    "plt.figure(figsize=(10, 8))\n",
    "if HAS_SEABORN:\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"vlag\", square=True)\n",
    "else:\n",
    "    plt.imshow(corr, cmap=\"coolwarm\", interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(len(corr)), corr.columns, rotation=45, ha='right')\n",
    "    plt.yticks(range(len(corr)), corr.columns)\n",
    "plt.title(\"Correlation matrix\")\n",
    "plt.tight_layout()\n",
    "corr_img = out_folder / \"correlation_heatmap.png\"\n",
    "plt.savefig(corr_img, dpi=150)\n",
    "plt.close()\n",
    "print(\"Saved correlation heatmap to:\", corr_img)\n",
    "print(\"Correlation CSV saved to:\", corr_file_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0cd896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Pairwise scatter (sampled if many rows) --------------\n",
    "max_pairs = 6  # limit number of vars for pairplot/pairs to keep plots readable\n",
    "cols_for_pairs = numeric_cols if len(numeric_cols) <= max_pairs else numeric_cols[:max_pairs]\n",
    "sample = df_num[cols_for_pairs].sample(n=min(1000, df_num.shape[0]), random_state=42)  # sampling for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c569072",
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_SEABORN:\n",
    "    sns.pairplot(sample, diag_kind=\"hist\", plot_kws=dict(s=20, alpha=0.6))\n",
    "    pair_file = out_folder / \"pairplot_sample.png\"\n",
    "    plt.gcf().set_size_inches(12, 10)\n",
    "    plt.savefig(pair_file, dpi=150)\n",
    "    plt.close()\n",
    "else:\n",
    "    pd.plotting.scatter_matrix(sample, alpha=0.5, figsize=(12, 12), diagonal='hist')\n",
    "    pair_file = out_folder / \"scatter_matrix_sample.png\"\n",
    "    plt.savefig(pair_file, dpi=150)\n",
    "    plt.close()\n",
    "print(\"Saved pairwise/sample scatter to:\", pair_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54048920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- PCA for 2D visualization (with scaling) --------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_num.fillna(df_num.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e0176",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "print(\"\\nPCA explained variance ratios (first 2):\", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d82703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of PCA (color by Award? if present)\n",
    "plt.figure(figsize=(8,6))\n",
    "if 'Award?' in df.columns:\n",
    "    # try to use Award? as categorical coloring if present\n",
    "    labels = df['Award?'].astype(str).values\n",
    "    # map labels to integers for color mapping\n",
    "    unique_labels = np.unique(labels)\n",
    "    label_map = {lab:i for i,lab in enumerate(unique_labels)}\n",
    "    colors = [label_map[l] for l in labels]\n",
    "    sc = plt.scatter(X_pca[:,0], X_pca[:,1], c=colors, alpha=0.6, s=20)\n",
    "    # legend\n",
    "    handles = []\n",
    "    for lab, i in label_map.items():\n",
    "        handles.append(plt.Line2D([0],[0], marker='o', color='w', label=str(lab),\n",
    "                                  markerfacecolor=plt.cm.tab10(i % 10), markersize=6))\n",
    "    plt.legend(handles=handles, title=\"Award?\")\n",
    "else:\n",
    "    plt.scatter(X_pca[:,0], X_pca[:,1], alpha=0.6, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeff8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"PCA (2D) visualization of numeric features\")\n",
    "pca_file = out_folder / \"pca_2d.png\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(pca_file, dpi=150)\n",
    "plt.close()\n",
    "print(\"Saved PCA 2D plot to:\", pca_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d381c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Save scaled numeric data for clustering stage --------------\n",
    "scaled_df = pd.DataFrame(X_scaled, columns=df_num.columns, index=df_num.index)\n",
    "scaled_out = out_folder / \"eastwest_scaled_numeric.csv\"\n",
    "scaled_df.to_csv(scaled_out, index=False)\n",
    "print(\"Saved scaled numeric features to:\", scaled_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35363354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Summary print for report --------------\n",
    "print(\"\\n--- EDA SUMMARY ---\")\n",
    "print(\"Rows:\", df.shape[0], \"Numeric cols:\", len(numeric_cols))\n",
    "print(\"Saved outputs in:\", out_folder)\n",
    "print(\"Files created:\")\n",
    "for f in [hist_file, box_file, corr_img, pair_file, pca_file, scaled_out, desc_file, corr_file_csv]:\n",
    "    print(\" -\", f)\n",
    "print(\"\\nYou can include the above PNGs and CSVs in your report. Next, we can run clustering on the scaled features (eastwest_scaled_numeric.csv).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1658170b",
   "metadata": {},
   "source": [
    "cluster2.py\n",
    "Clustering experiments: KMeans, Hierarchical (Agglomerative), DBSCAN\n",
    "Saves plots and cluster summaries next to the data file.\n",
    "Run in your venv: python cluster2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8cfcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c160a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional prettier plots\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    HAS_SEABORN = True\n",
    "except:\n",
    "    HAS_SEABORN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c086d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f766bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- CONFIG --------------\n",
    "DATA_PATH = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\8 clustering\\Clustering\\EastWestAirlines.csv\"\n",
    "# If you already have the scaled csv from earlier: set SCALED_CSV to that path; script will use it.\n",
    "SCALED_CSV = Path(DATA_PATH).parent / \"eastwest_scaled_numeric.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a252a239",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "OUT_DIR = Path(DATA_PATH).parent\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b1a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- LOAD / PREPROCESS --------------\n",
    "def load_prepared():\n",
    "    # Always load from the scaled CSV (skip Excel)\n",
    "    scaled_df = pd.read_csv(r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\8 clustering\\Clustering\\eastwest_scaled_numeric.csv\")\n",
    "    \n",
    "    # Use the same data for raw_num (no scaling reversal needed for clustering visuals)\n",
    "    raw_num = scaled_df.copy()\n",
    "    return raw_num, scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219e0a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_num, X_scaled_df = load_prepared()\n",
    "X = X_scaled_df.values\n",
    "cols = X_scaled_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b9ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for visualization coordinates\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X)\n",
    "print(\"PCA explained variance (first 2):\", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa601425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- VISUAL: PCA scatter (no clusters) --------------\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], s=10, alpha=0.6)\n",
    "plt.title(\"PCA (2D) - raw (no clusters)\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / \"pca_raw.png\", dpi=150)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e807ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- K-MEANS: Elbow + Silhouette sweep --------------\n",
    "Ks = list(range(2, 11))\n",
    "inertia = []\n",
    "sil_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b1e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in Ks:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X)\n",
    "    inertia.append(km.inertia_)\n",
    "    sil_scores.append(silhouette_score(X, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83101031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot elbow & silhouette\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(Ks, inertia, marker='o')\n",
    "plt.title(\"KMeans Elbow (Inertia)\")\n",
    "plt.xlabel(\"k\"); plt.ylabel(\"Inertia\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(Ks, sil_scores, marker='o')\n",
    "plt.title(\"KMeans Silhouette vs k\")\n",
    "plt.xlabel(\"k\"); plt.ylabel(\"Silhouette score\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / \"kmeans_elbow_silhouette.png\", dpi=150)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367d06ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = Ks[int(np.argmax(sil_scores))]\n",
    "print(\"KMeans: best k by silhouette in range 2-10:\", best_k, \"silhouette:\", max(sil_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e06ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=30)\n",
    "km_labels = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa948f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA plot colored by KMeans\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=km_labels, cmap='tab10', s=12, alpha=0.7)\n",
    "plt.title(f\"KMeans (k={best_k}) on PCA(2)\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / f\"kmeans_k{best_k}_pca.png\", dpi=150)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e8c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save KMeans results\n",
    "pd.DataFrame({'PC1': X_pca[:,0], 'PC2': X_pca[:,1], 'kmeans_label': km_labels}).to_csv(OUT_DIR / f\"kmeans_k{best_k}_pca_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6625aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KMeans cluster counts:\\n\", pd.Series(km_labels).value_counts())\n",
    "print(\"KMeans silhouette:\", silhouette_score(X, km_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64f679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Hierarchical (Agglomerative) --------------\n",
    "# Dendrogram (on subset for readability)\n",
    "sample_n = min(300, X.shape[0])\n",
    "sample_idx = np.random.choice(X.shape[0], size=sample_n, replace=False)\n",
    "Z = linkage(X[sample_idx], method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7e70a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "dendrogram(Z, truncate_mode='level', p=5)\n",
    "plt.title(\"Dendrogram (ward) - truncated\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / \"dendrogram_ward_truncated.png\", dpi=150)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8777e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkages = ['ward', 'complete', 'average']\n",
    "agg_results = {}\n",
    "for link in linkages:\n",
    "    # ward linkage requires 'euclidean' and can't be used if metric != euclidean (we have default)\n",
    "    ac = AgglomerativeClustering(n_clusters=best_k, linkage=link)\n",
    "    labels_ac = ac.fit_predict(X)\n",
    "    s = silhouette_score(X, labels_ac)\n",
    "    agg_results[link] = (labels_ac, s)\n",
    "    # plot\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.scatter(X_pca[:,0], X_pca[:,1], c=labels_ac, cmap='tab10', s=12, alpha=0.7)\n",
    "    plt.title(f\"Agglomerative ({link}) k={best_k} silhouette={s:.3f}\")\n",
    "    plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / f\"agg_{link}_k{best_k}_pca.png\", dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"Agglomerative ({link}) silhouette: {s:.4f} counts:\\n\", pd.Series(labels_ac).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157a2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save last agg's labels\n",
    "for link in linkages:\n",
    "    labels_ac, s = agg_results[link]\n",
    "    pd.DataFrame({'PC1': X_pca[:,0], 'PC2': X_pca[:,1], f'agg_{link}_label': labels_ac}).to_csv(OUT_DIR / f\"agg_{link}_k{best_k}_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4552a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- DBSCAN: choose eps by k-NN knee + sweep --------------\n",
    "# compute 5-NN distances sorted to inspect knee\n",
    "nbrs = NearestNeighbors(n_neighbors=5).fit(X)\n",
    "distances, _ = nbrs.kneighbors(X)\n",
    "kth_dist = np.sort(distances[:,4])\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(kth_dist)\n",
    "plt.title(\"Sorted 5-NN distances (knee indicates eps)\")\n",
    "plt.ylabel(\"5-NN distance\")\n",
    "plt.xlabel(\"sorted points\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / \"knn_5dist_sorted.png\", dpi=150)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93522ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep eps and min_samples\n",
    "eps_list = [0.3, 0.5, 0.7, 0.9, 1.1]\n",
    "min_samples_list = [4, 6, 8]\n",
    "best_db = None\n",
    "best_db_score = -1\n",
    "for eps in eps_list:\n",
    "    for ms in min_samples_list:\n",
    "        db = DBSCAN(eps=eps, min_samples=ms)\n",
    "        labels_db = db.fit_predict(X)\n",
    "        n_clusters = len(set(labels_db)) - (1 if -1 in labels_db else 0)\n",
    "        if n_clusters <= 1:\n",
    "            score = -1\n",
    "        else:\n",
    "            mask = labels_db != -1\n",
    "            try:\n",
    "                score = silhouette_score(X[mask], labels_db[mask])\n",
    "            except:\n",
    "                score = -1\n",
    "        print(f\"DBSCAN eps={eps}, min_samples={ms} -> clusters={n_clusters}, silhouette={score:.4f}, noise={(labels_db==-1).sum()}\")\n",
    "        if score > best_db_score:\n",
    "            best_db_score = score\n",
    "            best_db = (eps, ms, labels_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8acf29",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "if best_db is not None:\n",
    "    eps, ms, labels_db = best_db\n",
    "    print(\"Best DBSCAN:\", eps, ms, \"silhouette:\", best_db_score)\n",
    "    # save and plot\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.scatter(X_pca[:,0], X_pca[:,1], c=labels_db, cmap='tab10', s=12, alpha=0.7)\n",
    "    plt.title(f\"DBSCAN (eps={eps}, min_samples={ms})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / f\"dbscan_eps{eps}_ms{ms}_pca.png\", dpi=150)\n",
    "    plt.close()\n",
    "    pd.DataFrame({'PC1':X_pca[:,0],'PC2':X_pca[:,1],'dbscan_label':labels_db}).to_csv(OUT_DIR / f\"dbscan_eps{eps}_ms{ms}_labels.csv\", index=False)\n",
    "else:\n",
    "    print(\"DBSCAN did not find a stable multi-cluster solution in the tried grid.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590ed95",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# -------------- CLUSTER INTERPRETATION: cluster means on original-scale features --------------\n",
    "def summarize_clusters(original_df, labels, name):\n",
    "    # original_df should be the raw (unscaled) numeric dataframe aligned to labels rows\n",
    "    df_tmp = original_df.copy().reset_index(drop=True)\n",
    "    df_tmp['cluster'] = labels\n",
    "    summary = df_tmp.groupby('cluster').mean().T\n",
    "    summary_file = OUT_DIR / f\"{name}_cluster_feature_means.csv\"\n",
    "    summary.to_csv(summary_file)\n",
    "    print(f\"Saved cluster means for {name} to {summary_file}\")\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb8742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For kmeans:\n",
    "summary_km = summarize_clusters(raw_num.reset_index(drop=True).loc[X_scaled_df.index], km_labels, f\"kmeans_k{best_k}\")\n",
    "print(\"\\nKMeans cluster means (truncated):\")\n",
    "print(summary_km.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c72cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For hierarchical (ward)\n",
    "ward_labels, ward_s = agg_results['ward']\n",
    "summary_ward = summarize_clusters(raw_num.reset_index(drop=True).loc[X_scaled_df.index], ward_labels, \"agg_ward\")\n",
    "print(\"\\nAgglomerative(ward) cluster means (truncated):\")\n",
    "print(summary_ward.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc15b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_db is not None:\n",
    "    summary_db = summarize_clusters(raw_num.reset_index(drop=True).loc[X_scaled_df.index], labels_db, f\"dbscan_eps{eps}_ms{ms}\")\n",
    "    print(\"\\nDBSCAN cluster means (truncated):\")\n",
    "    print(summary_db.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1656ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- FINAL SUMMARY PRINT --------------\n",
    "print(\"\\n--- FINAL SUMMARY ---\")\n",
    "print(f\"KMeans k={best_k} silhouette={silhouette_score(X, km_labels):.4f}\")\n",
    "for link in linkages:\n",
    "    print(f\"Agglomerative ({link}) silhouette={agg_results[link][1]:.4f}\")\n",
    "if best_db is not None:\n",
    "    print(f\"Best DBSCAN eps={eps}, min_samples={ms} silhouette={best_db_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eae6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All plots and CSV outputs saved to:\", OUT_DIR)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
