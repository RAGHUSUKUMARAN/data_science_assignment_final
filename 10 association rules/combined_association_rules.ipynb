{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "071b4017",
   "metadata": {},
   "source": [
    "Step 2: Frequent Itemsets (single items) — support >= 5%\n",
    "Works with either:\n",
    " - transactions (list of lists) from preprocessing, OR\n",
    " - one-hot CSV saved from preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb6820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee54c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Config ----------\n",
    "MIN_SUPPORT = 0.05          # 5%\n",
    "total_transactions = None  # filled later\n",
    "# Input paths (change if needed)\n",
    "one_hot_csv_path = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\10 association rules\\Association Rules\\basket_one_hot.csv\"\n",
    "# If you have the transactions list in memory (from preprocessing), set it here:\n",
    "# transactions = [...]   # list of lists, each inner list = items (lowercased)\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aa4a1b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def frequent_items_from_transactions(transactions: List[List[str]], min_support: float):\n",
    "    \"\"\"\n",
    "    Count single-item supports from a list-of-lists transactions and return items >= min_support.\n",
    "    Returns a DataFrame: item | support | count\n",
    "    \"\"\"\n",
    "    n = len(transactions)\n",
    "    total_transactions_local = n\n",
    "    # Count occurrences (in how many transactions each item appears)\n",
    "    counter = Counter()\n",
    "    for tx in transactions:\n",
    "        unique_items = set(tx)  # ensure a transaction counts an item only once\n",
    "        counter.update(unique_items)\n",
    "    rows = []\n",
    "    for item, count in counter.items():\n",
    "        support = count / total_transactions_local\n",
    "        rows.append((item, support, count))\n",
    "    df = pd.DataFrame(rows, columns=[\"item\", \"support\", \"count\"]).sort_values(\"support\", ascending=False).reset_index(drop=True)\n",
    "    df = df[df[\"support\"] >= min_support]\n",
    "    return df, total_transactions_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2d2f6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def frequent_items_from_onehot(one_hot_df: pd.DataFrame, min_support: float):\n",
    "    \"\"\"\n",
    "    Compute supports directly from one-hot DataFrame where rows = transactions, cols = items (0/1).\n",
    "    \"\"\"\n",
    "    n = one_hot_df.shape[0]\n",
    "    support_series = one_hot_df.sum(axis=0) / n\n",
    "    counts = (one_hot_df.sum(axis=0)).astype(int)\n",
    "    df = pd.DataFrame({\n",
    "        \"item\": support_series.index,\n",
    "        \"support\": support_series.values,\n",
    "        \"count\": counts.values\n",
    "    }).sort_values(\"support\", ascending=False).reset_index(drop=True)\n",
    "    df = df[df[\"support\"] >= min_support]\n",
    "    return df, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e495d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Try to read one-hot CSV first; fallback to transactions variable if not available\n",
    "# -------------------------\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5621320",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(one_hot_csv_path):\n",
    "    print(\"Loading one-hot CSV from:\", one_hot_csv_path)\n",
    "    onehot = pd.read_csv(one_hot_csv_path, index_col=False)  # columns are items\n",
    "    # If your CSV saved with an index column, you may need index_col=0 — adjust if necessary.\n",
    "    # Ensure values are 0/1:\n",
    "    onehot = onehot.fillna(0).astype(int)\n",
    "    freq_df, total_transactions = frequent_items_from_onehot(onehot, MIN_SUPPORT)\n",
    "else:\n",
    "    print(\"One-hot CSV not found at the path. Looking for 'transactions' variable in memory...\")\n",
    "    try:\n",
    "        # Use the transactions list produced earlier in preprocessing step\n",
    "        transactions  # type: ignore\n",
    "        freq_df, total_transactions = frequent_items_from_transactions(transactions, MIN_SUPPORT)  # type: ignore\n",
    "    except NameError:\n",
    "        raise RuntimeError(\"No input found: place 'transactions' variable in memory or save one-hot CSV at one_hot_csv_path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f2732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print top results\n",
    "print(f\"\\nTotal transactions used: {total_transactions}\")\n",
    "print(f\"Items with support >= {MIN_SUPPORT*100:.1f}% (count >= {int(MIN_SUPPORT*total_transactions)}):\\n\")\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "print(freq_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40664f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the frequent single-item list to CSV for embedding in your assignment\n",
    "out_csv = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\10 association rules\\Association Rules\\frequent_items_single.csv\"\n",
    "freq_df.to_csv(out_csv, index=False)\n",
    "print(f\"\\nSaved frequent single-item list to: {out_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad56a1b",
   "metadata": {},
   "source": [
    "Quick tips:\n",
    "- If you want the top-k items only, do freq_df.head(k)\n",
    "- To change threshold, modify MIN_SUPPORT variable at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12731f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 2b: Pairwise frequent itemsets + association rules (support, confidence, lift)\n",
    "- Works from one-hot DataFrame (preferred) or transactions list.\n",
    "- Only considers pairs made from single items that meet min_support (Apriori pruning).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead55506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from typing import List, Tuple\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e053ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Config --------------------\n",
    "MIN_SUPPORT = 0.05          # minimum support threshold (fraction of transactions)\n",
    "MIN_CONFIDENCE = 0.0       # optional: filter rules with confidence >= this (0 to 1). Set 0 to keep all.\n",
    "ONE_HOT_CSV = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\10 association rules\\Association Rules\\basket_one_hot.csv\"\n",
    "OUT_RULES_CSV = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\10 association rules\\Association Rules\\pairwise_rules.csv\"\n",
    "# ------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f392dea",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_onehot_or_transactions(one_hot_path: str):\n",
    "    \"\"\"\n",
    "    Try loading one-hot CSV; otherwise expect `transactions` list to exist in memory.\n",
    "    Returns: (onehot_df, transactions_list)\n",
    "    One of them may be None depending on source.\n",
    "    \"\"\"\n",
    "    if os.path.exists(one_hot_path):\n",
    "        onehot = pd.read_csv(one_hot_path, index_col=False)\n",
    "        # Ensure binary 0/1\n",
    "        onehot = onehot.fillna(0).astype(int)\n",
    "        return onehot, None\n",
    "    else:\n",
    "        try:\n",
    "            # transactions variable should be a list of lists (from preprocessing)\n",
    "            transactions  # type: ignore\n",
    "            return None, transactions  # type: ignore\n",
    "        except NameError:\n",
    "            raise RuntimeError(\"No input found. Provide basket_one_hot.csv at ONE_HOT_CSV path or ensure 'transactions' exists in memory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfce4ea",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def compute_single_item_supports_from_onehot(onehot: pd.DataFrame) -> Tuple[pd.Series, int]:\n",
    "    n = onehot.shape[0]\n",
    "    support = onehot.sum(axis=0) / n\n",
    "    counts = onehot.sum(axis=0).astype(int)\n",
    "    return pd.DataFrame({\"support\": support, \"count\": counts}), n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab87dd1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def compute_single_item_supports_from_tx(transactions: List[List[str]]) -> Tuple[pd.DataFrame, int]:\n",
    "    from collections import Counter\n",
    "    n = len(transactions)\n",
    "    cnt = Counter()\n",
    "    for tx in transactions:\n",
    "        cnt.update(set(tx))\n",
    "    items = []\n",
    "    counts = []\n",
    "    supports = []\n",
    "    for itm, c in cnt.items():\n",
    "        items.append(itm)\n",
    "        counts.append(c)\n",
    "        supports.append(c / n)\n",
    "    df = pd.DataFrame({\"item\": items, \"support\": supports, \"count\": counts}).set_index(\"item\")\n",
    "    return df, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f77a90",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_pairwise_rules_from_onehot(onehot: pd.DataFrame, min_support: float, min_confidence: float):\n",
    "    single_df, n = compute_single_item_supports_from_onehot(onehot)\n",
    "    # Keep items that meet min_support (Apriori)\n",
    "    frequent_items = single_df[single_df[\"support\"] >= min_support].copy()\n",
    "    frequent_items = frequent_items.sort_values(\"support\", ascending=False)\n",
    "    items = frequent_items.index.tolist()\n",
    "\n",
    "    rules = []\n",
    "    for a, b in combinations(items, 2):\n",
    "        # pair support = count of transactions where both a and b = 1\n",
    "        pair_count = ((onehot[a] == 1) & (onehot[b] == 1)).sum()\n",
    "        pair_support = pair_count / n\n",
    "        if pair_support >= min_support:\n",
    "            support_a = frequent_items.loc[a, \"support\"]\n",
    "            support_b = frequent_items.loc[b, \"support\"]\n",
    "            # confidence a->b and b->a\n",
    "            conf_a_b = pair_support / support_a if support_a > 0 else 0.0\n",
    "            conf_b_a = pair_support / support_b if support_b > 0 else 0.0\n",
    "            lift = pair_support / (support_a * support_b) if (support_a * support_b) > 0 else 0.0\n",
    "\n",
    "            if conf_a_b >= min_confidence:\n",
    "                rules.append({\n",
    "                    \"antecedent\": a,\n",
    "                    \"consequent\": b,\n",
    "                    \"support\": pair_support,\n",
    "                    \"confidence\": conf_a_b,\n",
    "                    \"lift\": lift,\n",
    "                    \"pair_count\": int(pair_count)\n",
    "                })\n",
    "            if conf_b_a >= min_confidence:\n",
    "                rules.append({\n",
    "                    \"antecedent\": b,\n",
    "                    \"consequent\": a,\n",
    "                    \"support\": pair_support,\n",
    "                    \"confidence\": conf_b_a,\n",
    "                    \"lift\": lift,\n",
    "                    \"pair_count\": int(pair_count)\n",
    "                })\n",
    "\n",
    "    rules_df = pd.DataFrame(rules).sort_values(by=[\"lift\", \"confidence\"], ascending=False).reset_index(drop=True)\n",
    "    return rules_df, frequent_items, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091e8f8d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_pairwise_rules_from_tx(transactions: List[List[str]], min_support: float, min_confidence: float):\n",
    "    # Build a quick mapping of item -> set of transaction indices\n",
    "    item_to_tids = {}\n",
    "    for tid, tx in enumerate(transactions):\n",
    "        for itm in set(tx):\n",
    "            item_to_tids.setdefault(itm, set()).add(tid)\n",
    "    n = len(transactions)\n",
    "    # single support\n",
    "    single_support = {itm: len(tids)/n for itm, tids in item_to_tids.items()}\n",
    "    # frequent items\n",
    "    frequent_items = [itm for itm, sup in single_support.items() if sup >= min_support]\n",
    "    rules = []\n",
    "    for a, b in combinations(sorted(frequent_items), 2):\n",
    "        tids_a = item_to_tids[a]\n",
    "        tids_b = item_to_tids[b]\n",
    "        pair_tids = tids_a & tids_b\n",
    "        pair_count = len(pair_tids)\n",
    "        pair_support = pair_count / n\n",
    "        if pair_support >= min_support:\n",
    "            support_a = single_support[a]\n",
    "            support_b = single_support[b]\n",
    "            conf_a_b = pair_support / support_a if support_a > 0 else 0.0\n",
    "            conf_b_a = pair_support / support_b if support_b > 0 else 0.0\n",
    "            lift = pair_support / (support_a * support_b) if (support_a * support_b) > 0 else 0.0\n",
    "            if conf_a_b >= min_confidence:\n",
    "                rules.append({\"antecedent\": a, \"consequent\": b, \"support\": pair_support, \"confidence\": conf_a_b, \"lift\": lift, \"pair_count\": pair_count})\n",
    "            if conf_b_a >= min_confidence:\n",
    "                rules.append({\"antecedent\": b, \"consequent\": a, \"support\": pair_support, \"confidence\": conf_b_a, \"lift\": lift, \"pair_count\": pair_count})\n",
    "    rules_df = pd.DataFrame(rules).sort_values(by=[\"lift\", \"confidence\"], ascending=False).reset_index(drop=True)\n",
    "    # Convert frequent_items to DataFrame for convenience\n",
    "    freq_df = pd.DataFrame([(itm, int(len(item_to_tids[itm])), single_support[itm]) for itm in sorted(frequent_items)],\n",
    "                           columns=[\"item\", \"count\", \"support\"]).set_index(\"item\").sort_values(\"support\", ascending=False)\n",
    "    return rules_df, freq_df, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe454ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Run --------------------\n",
    "onehot, transactions = load_onehot_or_transactions(ONE_HOT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "if onehot is not None:\n",
    "    print(\"Using one-hot CSV as input.\")\n",
    "    rules_df, freq_items_df, total_tx = generate_pairwise_rules_from_onehot(onehot, MIN_SUPPORT, MIN_CONFIDENCE)\n",
    "else:\n",
    "    print(\"Using 'transactions' variable in memory as input.\")\n",
    "    rules_df, freq_items_df, total_tx = generate_pairwise_rules_from_tx(transactions, MIN_SUPPORT, MIN_CONFIDENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total transactions: {total_tx}\")\n",
    "print(f\"Frequent single items (support >= {MIN_SUPPORT}): {len(freq_items_df)}\\n\")\n",
    "print(\"Top 10 pairwise rules by lift:\")\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "print(rules_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05f5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "rules_df.to_csv(OUT_RULES_CSV, index=False)\n",
    "print(f\"\\nSaved pairwise rules to: {OUT_RULES_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e1ed0a",
   "metadata": {},
   "source": [
    "Step 1: Data Preprocessing for Association Rule Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ce155",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7cd09",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_transactions_from_file(path: str, col_index: int = 0):\n",
    "    \"\"\"\n",
    "    Load Excel/CSV file and return a list of transactions (list of lists).\n",
    "    Each transaction = list of items.\n",
    "    \"\"\"\n",
    "    if path.lower().endswith(('.xls', '.xlsx')):\n",
    "        df = pd.read_excel(path, engine=\"openpyxl\")\n",
    "    else:\n",
    "        df = pd.read_csv(path)\n",
    "    \n",
    "    raw_col = df.iloc[:, col_index].astype(str)\n",
    "\n",
    "    transactions = []\n",
    "    for basket_str in raw_col:\n",
    "        # Split by comma, strip spaces, lowercase\n",
    "        items = [itm.strip().lower() for itm in basket_str.split(',') if itm.strip()]\n",
    "        # Remove duplicates inside a basket\n",
    "        items = list(dict.fromkeys(items))  \n",
    "        transactions.append(items)\n",
    "\n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05baa384",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def transactions_to_ohe(transactions):\n",
    "    \"\"\"\n",
    "    Convert list-of-lists (transactions) to one-hot encoded DataFrame.\n",
    "    \"\"\"\n",
    "    tx_df = pd.DataFrame({'tid': range(len(transactions)), 'items': transactions})\n",
    "    tx_exploded = tx_df.explode('items').dropna(subset=['items'])\n",
    "    ohe = pd.crosstab(tx_exploded['tid'], tx_exploded['items'])\n",
    "    ohe = ohe.reindex(range(len(transactions)), fill_value=0)  # keep all transactions\n",
    "    return ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0cc20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Run preprocessing\n",
    "# -------------------------\n",
    "filepath = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\10 association rules\\Association Rules\\Online Retail.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4129831",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = load_transactions_from_file(filepath)\n",
    "print(f\"Total transactions loaded: {len(transactions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73c7fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick peek at first 5 transactions\n",
    "for i, t in enumerate(transactions[:5]):\n",
    "    print(f\"{i}: {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_ohe = transactions_to_ohe(transactions)\n",
    "print(\"\\nOne-hot encoded basket shape:\", basket_ohe.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(basket_ohe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8b30bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the one-hot encoded dataset if needed\n",
    "basket_ohe.to_csv(r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\10 association rules\\Association Rules\\basket_one_hot.csv\", index=False)\n",
    "print(\"\\nSaved one-hot file to basket_one_hot.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
