{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12731f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 2b: Pairwise frequent itemsets + association rules (support, confidence, lift)\n",
    "- Works from one-hot DataFrame (preferred) or transactions list.\n",
    "- Only considers pairs made from single items that meet min_support (Apriori pruning).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead55506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from typing import List, Tuple\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e053ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Config --------------------\n",
    "MIN_SUPPORT = 0.05          # minimum support threshold (fraction of transactions)\n",
    "MIN_CONFIDENCE = 0.0       # optional: filter rules with confidence >= this (0 to 1). Set 0 to keep all.\n",
    "ONE_HOT_CSV = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\10 association rules\\Association Rules\\basket_one_hot.csv\"\n",
    "OUT_RULES_CSV = r\"D:\\DATA SCIENCE\\ASSIGNMENTS\\10 association rules\\Association Rules\\pairwise_rules.csv\"\n",
    "# ------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f392dea",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_onehot_or_transactions(one_hot_path: str):\n",
    "    \"\"\"\n",
    "    Try loading one-hot CSV; otherwise expect `transactions` list to exist in memory.\n",
    "    Returns: (onehot_df, transactions_list)\n",
    "    One of them may be None depending on source.\n",
    "    \"\"\"\n",
    "    if os.path.exists(one_hot_path):\n",
    "        onehot = pd.read_csv(one_hot_path, index_col=False)\n",
    "        # Ensure binary 0/1\n",
    "        onehot = onehot.fillna(0).astype(int)\n",
    "        return onehot, None\n",
    "    else:\n",
    "        try:\n",
    "            # transactions variable should be a list of lists (from preprocessing)\n",
    "            transactions  # type: ignore\n",
    "            return None, transactions  # type: ignore\n",
    "        except NameError:\n",
    "            raise RuntimeError(\"No input found. Provide basket_one_hot.csv at ONE_HOT_CSV path or ensure 'transactions' exists in memory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfce4ea",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def compute_single_item_supports_from_onehot(onehot: pd.DataFrame) -> Tuple[pd.Series, int]:\n",
    "    n = onehot.shape[0]\n",
    "    support = onehot.sum(axis=0) / n\n",
    "    counts = onehot.sum(axis=0).astype(int)\n",
    "    return pd.DataFrame({\"support\": support, \"count\": counts}), n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab87dd1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def compute_single_item_supports_from_tx(transactions: List[List[str]]) -> Tuple[pd.DataFrame, int]:\n",
    "    from collections import Counter\n",
    "    n = len(transactions)\n",
    "    cnt = Counter()\n",
    "    for tx in transactions:\n",
    "        cnt.update(set(tx))\n",
    "    items = []\n",
    "    counts = []\n",
    "    supports = []\n",
    "    for itm, c in cnt.items():\n",
    "        items.append(itm)\n",
    "        counts.append(c)\n",
    "        supports.append(c / n)\n",
    "    df = pd.DataFrame({\"item\": items, \"support\": supports, \"count\": counts}).set_index(\"item\")\n",
    "    return df, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f77a90",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_pairwise_rules_from_onehot(onehot: pd.DataFrame, min_support: float, min_confidence: float):\n",
    "    single_df, n = compute_single_item_supports_from_onehot(onehot)\n",
    "    # Keep items that meet min_support (Apriori)\n",
    "    frequent_items = single_df[single_df[\"support\"] >= min_support].copy()\n",
    "    frequent_items = frequent_items.sort_values(\"support\", ascending=False)\n",
    "    items = frequent_items.index.tolist()\n",
    "\n",
    "    rules = []\n",
    "    for a, b in combinations(items, 2):\n",
    "        # pair support = count of transactions where both a and b = 1\n",
    "        pair_count = ((onehot[a] == 1) & (onehot[b] == 1)).sum()\n",
    "        pair_support = pair_count / n\n",
    "        if pair_support >= min_support:\n",
    "            support_a = frequent_items.loc[a, \"support\"]\n",
    "            support_b = frequent_items.loc[b, \"support\"]\n",
    "            # confidence a->b and b->a\n",
    "            conf_a_b = pair_support / support_a if support_a > 0 else 0.0\n",
    "            conf_b_a = pair_support / support_b if support_b > 0 else 0.0\n",
    "            lift = pair_support / (support_a * support_b) if (support_a * support_b) > 0 else 0.0\n",
    "\n",
    "            if conf_a_b >= min_confidence:\n",
    "                rules.append({\n",
    "                    \"antecedent\": a,\n",
    "                    \"consequent\": b,\n",
    "                    \"support\": pair_support,\n",
    "                    \"confidence\": conf_a_b,\n",
    "                    \"lift\": lift,\n",
    "                    \"pair_count\": int(pair_count)\n",
    "                })\n",
    "            if conf_b_a >= min_confidence:\n",
    "                rules.append({\n",
    "                    \"antecedent\": b,\n",
    "                    \"consequent\": a,\n",
    "                    \"support\": pair_support,\n",
    "                    \"confidence\": conf_b_a,\n",
    "                    \"lift\": lift,\n",
    "                    \"pair_count\": int(pair_count)\n",
    "                })\n",
    "\n",
    "    rules_df = pd.DataFrame(rules).sort_values(by=[\"lift\", \"confidence\"], ascending=False).reset_index(drop=True)\n",
    "    return rules_df, frequent_items, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091e8f8d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_pairwise_rules_from_tx(transactions: List[List[str]], min_support: float, min_confidence: float):\n",
    "    # Build a quick mapping of item -> set of transaction indices\n",
    "    item_to_tids = {}\n",
    "    for tid, tx in enumerate(transactions):\n",
    "        for itm in set(tx):\n",
    "            item_to_tids.setdefault(itm, set()).add(tid)\n",
    "    n = len(transactions)\n",
    "    # single support\n",
    "    single_support = {itm: len(tids)/n for itm, tids in item_to_tids.items()}\n",
    "    # frequent items\n",
    "    frequent_items = [itm for itm, sup in single_support.items() if sup >= min_support]\n",
    "    rules = []\n",
    "    for a, b in combinations(sorted(frequent_items), 2):\n",
    "        tids_a = item_to_tids[a]\n",
    "        tids_b = item_to_tids[b]\n",
    "        pair_tids = tids_a & tids_b\n",
    "        pair_count = len(pair_tids)\n",
    "        pair_support = pair_count / n\n",
    "        if pair_support >= min_support:\n",
    "            support_a = single_support[a]\n",
    "            support_b = single_support[b]\n",
    "            conf_a_b = pair_support / support_a if support_a > 0 else 0.0\n",
    "            conf_b_a = pair_support / support_b if support_b > 0 else 0.0\n",
    "            lift = pair_support / (support_a * support_b) if (support_a * support_b) > 0 else 0.0\n",
    "            if conf_a_b >= min_confidence:\n",
    "                rules.append({\"antecedent\": a, \"consequent\": b, \"support\": pair_support, \"confidence\": conf_a_b, \"lift\": lift, \"pair_count\": pair_count})\n",
    "            if conf_b_a >= min_confidence:\n",
    "                rules.append({\"antecedent\": b, \"consequent\": a, \"support\": pair_support, \"confidence\": conf_b_a, \"lift\": lift, \"pair_count\": pair_count})\n",
    "    rules_df = pd.DataFrame(rules).sort_values(by=[\"lift\", \"confidence\"], ascending=False).reset_index(drop=True)\n",
    "    # Convert frequent_items to DataFrame for convenience\n",
    "    freq_df = pd.DataFrame([(itm, int(len(item_to_tids[itm])), single_support[itm]) for itm in sorted(frequent_items)],\n",
    "                           columns=[\"item\", \"count\", \"support\"]).set_index(\"item\").sort_values(\"support\", ascending=False)\n",
    "    return rules_df, freq_df, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe454ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Run --------------------\n",
    "onehot, transactions = load_onehot_or_transactions(ONE_HOT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "if onehot is not None:\n",
    "    print(\"Using one-hot CSV as input.\")\n",
    "    rules_df, freq_items_df, total_tx = generate_pairwise_rules_from_onehot(onehot, MIN_SUPPORT, MIN_CONFIDENCE)\n",
    "else:\n",
    "    print(\"Using 'transactions' variable in memory as input.\")\n",
    "    rules_df, freq_items_df, total_tx = generate_pairwise_rules_from_tx(transactions, MIN_SUPPORT, MIN_CONFIDENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total transactions: {total_tx}\")\n",
    "print(f\"Frequent single items (support >= {MIN_SUPPORT}): {len(freq_items_df)}\\n\")\n",
    "print(\"Top 10 pairwise rules by lift:\")\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "print(rules_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05f5fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "rules_df.to_csv(OUT_RULES_CSV, index=False)\n",
    "print(f\"\\nSaved pairwise rules to: {OUT_RULES_CSV}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
